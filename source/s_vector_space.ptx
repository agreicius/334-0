<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="s_vector_space" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Vector spaces</title>
        <p>
            In the last section we isolated useful number system properties of <m>\R</m> and generalized them in the form of our axiomatic definition of a field (<xref ref="d_field"/>). Similarly, in this section we give a similar treatment to the type of vector spaces usually studied in a first course in linear algebra: that is, the space of real <m>n</m>-tuples <m>\R^n=\{(a_1,a_2,\dots, a_n)\colon a_i\in \R\}</m>. The two operations on <m>\R^n</m> we choose to generalize are its version of <em>vector addition</em> 
            <md>
                <mrow>\R^n\times \R^n \amp \rightarrow \R^n</mrow>
                <mrow> ((a_1,a_2,\dots, a_n),(b_1,b_2,\dots, b_n))\amp\mapsto (a_1+b_1, a_2+b_2,\dots, a_n+b_n) </mrow>
            </md>,
            and its version of <em>scalar multiplication</em>
            <md>
                <mrow>\R\times \R^n \amp \rightarrow \R^n</mrow>
                <mrow>(c,(a_1,a_2,\dots, a_n)) \amp\rightarrow (ca_1,ca_2,\dots, ca_n) </mrow>
            </md>.
            You should think of the axioms of <xref ref="d_vector_space"/> as an enumeration of precisely which properties of these two operations on <m>\R^n</m> we want a structure to enjoy in order to ensure that we can perform a form of vector arithmetic and algebra just as we do in <m>\R^n</m>. Note that there is an important <em>qualitative</em> difference between the two vector operations on <m>\R^n</m> that is treated carefully in <xref ref="d_vector_space"/>; namely, whereas vector addition takes as its input two vectors <m>v,w\in \R^n</m> and returns another, scalar multiplication takes a scalar <m>c\in \R</m> and a vector <m>v\in \R^n</m> and returns another vector. In this sense, scalar multiplication should be thought of as a sort of <em>hybrid</em> operation. 
        </p>
     <assumption xml:id="fiat_F_field">
            <title><m>F</m> stands for field</title>
            <statement>
                <p>
                    Henceforth, unless stated otherwise, <m>F</m> will always denote a field. For any explicit example in this course the field <m>F</m> will be either <m>\R</m> or <m>\C</m>. However, all statements of theory formulated in terms of <m>F</m> are understood to be valid for any field. 
                </p>
            </statement>
        </assumption>
    <definition xml:id="d_vector_space">
        <title>Vector space</title>
        <idx><h>vector space</h><h>definition</h></idx>
        <idx><h>vector space</h><h>zero vector</h></idx>
        <idx><h>vector space</h><h>vector inverse</h></idx>
        <idx><h>vector space</h><h>vector</h></idx>
          <statement>
            <p>
              Let <m>F</m> be a field.  A <term>vector space over <m>F</m></term> (or <term><m>F</m>-vector space</term>) is a set <m>V</m> together with two operations
              <md>
                <mrow>V\times V \amp \rightarrow V \amp F\times V\amp \rightarrow V</mrow>
                <mrow>(v,w) \amp\mapsto v+w \amp (c,v)\amp \mapsto cv </mrow>
              </md>, 
              called respectively <term>vector addition</term> and <term>scalar multiplication</term>, that satisfy the following <term>vector space axioms</term>. 
            <ol marker="(i)" cols="2">
              <li>
                <title>Vector addition is commutative</title>
                <p>
                <m>v+w=w+v</m> for all <m>v,w\in V</m>.
                </p>
              </li>
              <li>
                <title>Vector addition is associative</title>
                <p>
                    <m>(u+v)+w=u+(v+w)</m> for all <m>u, v, w\in V</m>.
                </p>
              </li>
              <li xml:id="eq_d_zero_vector">
                <title>Zero vector</title>
                <p>
                  There is an element <m>\boldzero\in V</m> such that for all <m>v\in V</m>, we have
                  <men xml:id="eq_zero_vector">
                    \boldzero+v=v
                  </men>. We call <m>\boldzero</m> the <term>zero vector</term>  of <m>V</m>.
                </p>
              </li>
              <li xml:id="eq_d_vec_inverse">
                <title>Vector inverses</title>
                <p>
                For all <m>v\in V</m>, there is another element <m>-v</m> satisfying
                <men xml:id="eq_vec_inv">
                  -v+v=\boldzero
                </men>.
                We call <m>-v</m> the <term>vector inverse</term>  of <m>v</m>.
                </p>
              </li>
              <li>
                <title>Distribution over vector addition</title>
                <p>
                <m>
                  c(v+w)=cv+cw
                </m> for all <m>c\in F</m> and <m>v, w\in V</m>.
                </p>
              </li>
              <li>
                <title>Distribution over scalar addition</title>
                <p>
                  <m>
                    (c+d)v=cv+dv
                  </m>
                  for all <m>c,d\in F</m> and <m>v\in V</m>.
                </p>
              </li>
              <li>
                <title>Scalar multiplication is associative</title>
                <p>
                <m>
                  c(dv)=(cd)v
                </m>
                for all <m>c,d\in F</m> and all <m>v\in V</m>.
                </p>
              </li>
              <li>
                <title>Scalar multiplication identity</title>
                <p>
                    <m>
                        1\,v=v
                      </m> for all <m>v\in V</m>.
                </p>
              </li>
            </ol>
          We call elements of the vector space <m>V</m> <term>vectors</term> and the elements of <m>F</m> <term>scalars</term>. 
          </p>
      </statement>
        </definition>
        <remark>
            <title>Arithmetic and existential axioms</title>
            <p>
                As with the axioms in <xref ref="d_field"/> we divide the vector space axioms into the <em>arithmetic axioms</em> (Axioms (i)-(ii),(v)-(vi),(vii)) and the <em>existential axioms</em> (Axioms (iii)-(iv)). 
            </p>
        </remark>
        <p>
            We now proceed to a litany of examples. Each one will be stated as a definition (for reference purposes), but nonetheless requires a proof that the given structure does indeed constitute a vector space. In a classic mathematical move, we begin with the simplest of all vector spaces, the <em>zero space</em>. Elementary as this example is, it serves well to illustrate the axiomatic nature of <xref ref="d_vector_space"/>. 
        </p>
          <definition xml:id="d_zero_space">
            <title>Zero space</title>
            <statement>
                <p>
                    Let <m>F</m> be a field, and let <m>V=\{\bot\}</m>, a set containing exactly one element. There is a unique <m>F</m>-vector space structure that can be given to <m>V</m>, defined as follows. 
                    <ul>
                        <li>
                            <title>Vector operations</title>
                            <p>
                                Vector addition on <m>V</m> is defined as <m>\bot+\bot=\bot</m>; scalar multiplication on <m>V</m> is defined as <m>c\cdot \bot=\bot</m> for all <m>c\in F</m>. 
                            </p>
                        </li>
                        <li>
                            <title>Zero vector</title>
                            <p>
                                The zero vector of <m>V</m> is <m>\bot</m>: <ie/>, <m>\boldzero=\bot</m>.
                            </p>
                        </li>
                        <li>
                            <title>Vector inverses</title>
                            <p>
                                The vector inverse of <m>\bot</m> is <m>\bot</m>: <ie/>, <m>-\bot=\bot</m>. 
                            </p>
                        </li>
                    </ul>
                    Since <m>\bot=\boldzero</m> with respect to this vector space structure, we have <m>V=\{\boldzero\}</m>. Accordingly, we call <m>V</m> a <term>zero space</term>. 
                </p>   
            </statement>
        </definition>
        <p>
            <xref ref="d_zero_space"/> makes two claims: that the given operations make <m>V=\{\bot\}</m> into a vector space, and that this is the <em>only</em> way to make <m>V=\{\bot\}</m> into a vector space. As with all claims in mathematics, these need to be proved, but as you will see, the proof is a very light affair. 
        </p>
        <proof>
            <title>Proof for <xref ref="d_zero_space"/></title>
            <p>
                Since <m>V=\{\bot\}</m> only has one item, there is no choice for what vector addition <m>V\times V\rightarrow V</m> and scalar multiplication <m>F\times V\rightarrow V</m> can be. They must be defined in the manner given in <xref ref="d_zero_space"/>. Similarly, we must have <m>\boldzero=\bot</m> and <m>-\bot=\bot</m>, as once again, <m>\bot</m> is the only element of <m>V</m>! This shows that there can be <em>at most</em> one way of giving <m>V</m> a vector space structure. 
            </p>
            <p>
                It is now easy to see that these choices do indeed satisfy the vector space axioms. That <m>\bot</m> satisfies the identity of <xref ref="eq_d_zero_vector">Axiom</xref> defining the zero vector <m>\boldzero</m> follows from the fact that 
                for all <m>v\in V</m> we have <m>v=\bot</m> (since <m>V=\{\bot\}</m>), and thus 
                    <md>
                        <mrow>\bot+v \amp =\bot+\bot</mrow>
                        <mrow> \amp = \bot</mrow>
                        <mrow> \amp =v</mrow>
                    </md>.
                    Thus <m>\bot=\boldzero</m> is the zero vector of the space. 
            </p>
            <p>
                Similarly, to show all elements of <m>V</m> have vector inverses amounts to showing that <m>\bot</m> has a vector inverse, since this is the only element of <m>V</m>. It is claimed that <m>-\bot=\bot</m> (<ie/>, <m>\bot</m> is its own vector inverse), which follows from the fact that 
                <md>
                    <mrow>-\bot+\bot \amp = \bot+\bot</mrow>
                    <mrow> \amp = \bot</mrow>
                    <mrow> \amp = \boldzero</mrow>
                </md>.
                Lastly, the identities of Axioms (i)-(ii) and (v)-(viii) in this setting all reduce to trivial statements of the form <m>\bot+\bot=\bot+\bot</m>. Consider Axiom (vii), for example. For all <m>v,w\in V</m>, we have <m>v=w=\bot</m>, in which case
                <md>
                    <mrow>c(v+w) \amp =c(\bot+\bot) </mrow>
                    <mrow> \amp =c\cdot \bot</mrow>
                    <mrow> \amp = \bot \amp \text{(def. of sc. mult.)}</mrow>
                </md> and 
                <md>
                    <mrow>cv+dw \amp =c\cdot \bot+d\cdot \bot</mrow>
                    <mrow> \amp = \bot+\bot</mrow>
                    <mrow> \amp =\bot</mrow>
                </md>.
                Thus 
                <me>
                    c(v+w)=\bot=cv+dw 
                </me>
                for all <m>v, w\in V</m> and <m>c\in F</m>. 
            </p>
            <p>
                We leave verification of the rest of the axioms to the reader. 
            </p>
        </proof>
    <p>
        It is worth formalizing the proof technique used above into an official procedure for showing whether something is a vector space. 
    </p>
    <algorithm xml:id="proc_vector_space">
        <title>Vector space verification</title>
        
        <statement>
            <p>
To decide whether a given set and operations is a vector space, proceed as follows. 
<ol>
  <li>
    <p>
      Make explicit the underlying set <m>V</m> of the proposed vector space.
    </p>
  </li>
  <li>
    <p>
      Make explicit what the scalar multiplication and vector addition operations are.
    </p>
  </li>
  <li>
    <p>
      Identify an element of <m>V</m> that serves as the zero vector (<ie/>, satisfies <xref ref="eq_zero_vector"/>) and for each <m>\boldv\in V</m> show that there is a vector <m>-\boldv</m> satisfying <xref ref="eq_vec_inv"/>.
    </p>
  </li>
  <li>
    <p>
      Show that the two vector operations and our choice of zero vector and vector inverses satisfy the axioms of <xref ref="d_vector_space"/>.
    </p>
  </li>
</ol>
</p>
    </statement>
    </algorithm>
<remark>
    <title>Vector space verification</title>
    <p>
        Think of steps (1)-(3) of <xref ref="proc_vector_space"/> as the issuing of official declarations about the makeup of our proposed vector space: <q>The underlying set shall be as stated</q>; <q>We declare the vector operations thusly</q>; <q>The zero vector shall be this element here, and vector inverses shall be assigned in this manner</q>. Step (4) is where we get down to the nitty gritty of showing that the proposed vector space structure articulated in (1)-(3) does indeed satisfy all the necessary properties.
</p>
<p>
In each of the remaining examples below we carefully lay out the details of items (1)-(3) while often leaving much of the work of item (4) to you. You will meet these vector spaces frequently throughout the rest of your life. Each time you do, it will be helpful for orientation purposes to mentally run through items (1)-(3). Ask yourself: What is the underlying set? What are vector operations? What acts as the zero vector, and how do I assign vector inverses?
    </p>
</remark>

<p>
 We now work our way up in complexity, considering first three examples that might already be familiar to you in some form or other. Note that (a) the vector space operations for each of <xref ref="d_ntuples"/>, <xref ref="d_infinite_sequences_space"/>, <xref ref="d_matrix_space"/> are all very similar in nature (roughly speaking the operations are always defined <q>component-wise</q>), and (b) that we postpone the verification of the vector space axioms for these examples until <xref ref="th_vs_egs"/> in the next section! This is because each of the vector spaces in <xref first="d_ntuples" last="d_matrix_space"/> is in fact one particular example of the vastly more general vector space defined in <xref ref="d_tuple_space"/>! We will make this clear in the proof of <xref ref="th_vs_egs"/>. For now, consider the treatment of the vector spaces below simply as a <q>getting to know</q> session. 
</p>
<definition xml:id="d_ntuples">
  <title><m>n</m>-tuples</title>
  <statement>
    <p>
      Let <m>F</m> be a field. Given a positive integer <m>n</m>, recall that <m>F^n</m> is the set of all <m>F</m>-valued <m>n</m>-tuples: <ie/>, 
      <me>
        F^n=\{(a_1,a_2,\dots, a_n)\colon a_i\in F\}
      </me>.
      Below we define a vector space structure on <m>F^n</m>. 
      <ul>
        <li>
          <title>Vector operations</title>
          <p>
            Given <m>v=(a_1,a_2,\dots, a_n), w=(b_1,b_2,\dots, b_n)\in F^n</m> and <m>c\in \F</m>, we define 
            <md>
              <mrow>v+w \amp =(a_1+b_1,a_2+b_2,\cdots, a_n+b_n)</mrow>
              <mrow>cv \amp =(ca_1,ca_2,\dots, ca_n)</mrow>
            </md>.
          </p>
        </li>
        <li>
          <title>Zero vector</title>
          <p>
            The zero vector of <m>F^n</m> is <m>\boldzero=(0,0,\dots, 0)</m>. 
          </p>
        </li>
        <li>
          <title>Vector inverses</title>
          <p>
            Given a sequence <m>v=(a_1,a_2,\dots, a_n)\in F^n</m>, its vector inverse <m>-v</m> is 
            <me>
              -v=(-a_1,-a_2,\dots, -a_n)
            </me>.
          </p>
        </li>
      </ul>
    We call <m>F^n</m>, together with these vector operations, the <term>space of <m>F</m>-valued <m>n</m>-tuples</term> (or the <term>space of <m>n</m>-tuples with coordinates in <m>F</m></term>). 
    </p>
  </statement>
</definition>
<proof>
    <p>
        The proof that <m>F^n</m> is a vector space with respect to these operations is postponed until <xref ref="th_vs_egs"/>. 
    </p>
</proof>
<example xml:id="eg_complex_pairs">
<title>Complex pairs</title>
<statement>
<p>
Consider the complex vector space <m>\C^2=\{(z,w)\colon z,w\in \C\}</m>. Given vectors <m>v=(1+i, 2i), w=(i, 5)\in \C^2</m> and scalar <m>1-i\in \C</m>, we have 
<md>
    <mrow>v+w \amp = (1+2i, 5+2i)</mrow>
    <mrow>(1-i)v \amp =((1-i)(1+i),(1-i)2i)</mrow>
    <mrow> \amp = (2,2+2i)</mrow>
</md>.
</p>
</statement>
</example>


<definition xml:id="d_infinite_sequences_space">
<title>Space of infinite sequences</title>
<statement>
<p>
  Let <m>F</m> be a field. Recall that <m>F^\infty</m> is the set of all <m>F</m>-valued infinite sequences: <ie/>, 
  <me>
    F^\infty=\{(a_i)_{i=1}^\infty\colon a_i\in F \text{ for all } i\in \Z_+\}
  </me>.
  Below we define a vector space structure on <m>F^\infty</m>.
  <ul>
    <li>
      <title>Vector operations</title>
      <p>
        Given <m>s=(a_i)_{i=1}^\infty, t=(b_i)_{i=1}^\infty\in F^\infty</m> and <m>c\in F</m>, we define 
        <md>
          <mrow>s+t\amp=(a_i+b_i)_{i=1}^\infty=(a_1+b_1, a_2+b_2,\dots) </mrow>
          <mrow>cs \amp =(ca_i)_{i=1}^\infty=(ca_1,ca_2,\dots) </mrow>
        </md>.
      </p>
    </li>
    <li>
      <title>Zero vector</title>
      <p>
        The zero vector of <m>F^\infty</m> with respect to these operations is 
        <me>
          \boldzero=(0)_{i=1}^\infty=(0,0,\dots)
        </me>.
      </p>
    </li>
    <li>
      <title>Vector inverses</title>
      <p>
        Given a sequence <m>s=(a_i)_{i=1}^\infty\in F^\infty</m>, its vector inverse is 
        <md>
          <mrow>-s \amp = (-a_i)_{i=1}^\infty=(-a_1,-a_2,\dots )</mrow>
        </md>.
      </p>
    </li>
  </ul>
We call <m>F^\infty</m>, together with these vector operations, the <term>space of infinite sequences with entries in <m>F</m></term> (or the <term>space of <m>F</m>-valued infinite sequences</term>).
</p>
</statement>
</definition>
<proof>
    <p>
        The proof that <m>F^n</m> is a vector space with respect to these operations is postponed until <xref ref="th_vs_egs"/>. 
    </p>
</proof>
<example xml:id="eg_complex_seqs">
<title>Complex infinite sequences</title>
<statement>
<p>
Consider the complex vector space <m>\C^\infty</m> of all infinite sequences with complex entries. Given sequences <m>s=(0,1,0,1,0,\dots)</m> and <m>t=(i,i,i,\dots) </m>, and scalar <m>i\in \C</m>, we have 
<md>
    <mrow>s+t \amp =(i,i+1,i,i+1,i,\dots)</mrow>
    <mrow>it \amp =(i^2,i^2,\dots)</mrow>
    <mrow> \amp =(-1,-1,\dots )</mrow>
</md>.
</p>
</statement>
</example>


<definition xml:id="d_matrix_space">
<title>Space of matrices</title>
<statement>
<p>
Let <m>F</m> be a field. Given positive integers <m>m,n\in\Z_+</m>, we define <m>F^{m,n}</m> to be the set of all <m>m\times n</m> matrices with entries in <m>F</m>: <ie/>, 
<me>
  F^{m,n}=\{\underset{m\times n}{A}=[a_{ij}]\colon a_{ij}\in F \text{ for all } (i,j)\in \{1,2\dots, m\}\times \{1,2,\dots, n\}\}
</me>.
Below we define a vector space structure on <m>F^{m,n}</m>. 
<ul>
  
  <li>
    <title>Vector operations</title>
    <p>
      Given matrices <m>A=[a_{ij}], B=[b_{ij}]\in F^{m,n}</m> and <m>c\in F</m>, we define 
      <md>
        <mrow>A+B \amp =[a_{ij}+b_{ij}]</mrow>
        <mrow>cA \amp =[ca_{ij}]</mrow>
      </md>.
    </p>
  </li>
  <li>
    <title>Zero vector</title>
    <p>
      The zero vector of <m>F^{m,n}</m> is the the zero matrix 
      <me>
        \boldzero=[0]_{\substack{1\leq i\leq m\\ 1\leq j\leq n}}
      </me>.
    </p>
  </li>
  <li>
    <title>Vector inverses</title>
    <p>
      Given a matrix <m>A=[a_{ij}]\in F^{m,n}</m> its vector inverse is
      <me>
        -A=[-a_{ij}]
      </me>.
    </p>
  </li>
</ul>
We call <m>F^{m,n}</m>, together with these vector operations, the <term>space of <m>m\times n</m> matrices with entries in <m>F</m></term> (or the <term>space of <m>F</m>-valued <m>m\times n</m> matrices</term>).
</p>
</statement>
</definition>
<proof>
    <p>
        The proof that <m>F^n</m> is a vector space with respect to these operations is postponed until <xref ref="th_vs_egs"/>. 
    </p>
</proof>
<example xml:id="eg_complex_matrices">
<title>Complex matrices</title>
<statement>
<p>
Consider the vector space <m>\C^{2,2}</m> of all <m>2\times 2</m> matrices with complex entries. Given matrices 
<md>
    <mrow>A \amp = \begin{bmatrix}2i\amp 1+i \\ 0 \amp 3\end{bmatrix} </mrow>
    <mrow>B \amp = \begin{bmatrix}-3-i\amp 2 \\ i \amp 4+4i\end{bmatrix} </mrow>
</md>
and scalar <m>1+i\in \C</m>, we have 
<md>
    <mrow>A+B\amp = \begin{bmatrix}-3-i\amp 3+i \\ i \amp 7+4i\end{bmatrix} </mrow>
    <mrow>(1+i)A \amp = \begin{bmatrix}-2+2i\amp 2i \\ 0 \amp 3+3i\end{bmatrix} </mrow>
</md>.
</p>
</statement>
</example>


</section>