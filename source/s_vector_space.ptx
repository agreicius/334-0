<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="s_vector_space" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Vector spaces</title>

    <subsection xml:id="ss_vector_space_def">
    <title>Definitions and examples</title>
     <assumption xml:id="fiat_F_field">
            <title><m>F</m> stands for field</title>
            <statement>
                <p>
                    Henceforth, unless stated otherwise, <m>F</m> will always denote a field. For any explicit example in this course the field <m>F</m> will be either <m>\R</m> or <m>\C</m>. However, all statements of theory formulated in terms of <m>F</m> are understood to be valid for any field. 
                </p>
            </statement>
        </assumption>
    <definition xml:id="d_vector_space">
        <title>Vector space</title>
        <idx><h>vector space</h><h>definition</h></idx>
        <idx><h>vector space</h><h>zero vector</h></idx>
        <idx><h>vector space</h><h>vector inverse</h></idx>
        <idx><h>vector space</h><h>vector</h></idx>
          <statement>
            <p>
              Let <m>F</m> be a field.  A <term>vector space over <m>F</m></term> (or <term><m>F</m>-vector space</term>) is a set <m>V</m> together with two operations
              <md>
                <mrow>V\times V \amp \rightarrow V \amp F\times V\amp \rightarrow V</mrow>
                <mrow>(v,w) \amp\mapsto v+w \amp (c,v)\amp \mapsto cv </mrow>
              </md>, 
              called respectively <term>vector addition</term> and <term>scalar multiplication</term>, that satisfy the following <term>vector space axioms</term>. 
            <ol marker="(i)" cols="2">
              <li>
                <title>Vector addition is commutative</title>
                <p>
                <m>v+w=w+v</m> for all <m>v,w\in V</m>.
                </p>
              </li>
              <li>
                <title>Vector addition is associative</title>
                <p>
                    <m>(u+v)+w=u+(v+w)</m> for all <m>u, v, w\in V</m>.
                </p>
              </li>
              <li xml:id="eq_d_zero_vector">
                <title>Zero vector</title>
                <p>
                  There is an element <m>\boldzero\in V</m> such that for all <m>v\in V</m>, we have
                  <men xml:id="eq_zero_vector">
                    \boldzero+v=v
                  </men>. We call <m>\boldzero</m> the <term>zero vector</term>  of <m>V</m>.
                </p>
              </li>
              <li xml:id="eq_d_vec_inverse">
                <title>Vector inverses</title>
                <p>
                For all <m>v\in V</m>, there is another element <m>-v</m> satisfying
                <men xml:id="eq_vec_inv">
                  -v+v=\boldzero
                </men>.
                We call <m>-v</m> the <term>vector inverse</term>  of <m>v</m>.
                </p>
              </li>
              <li>
                <title>Distribution over vector addition</title>
                <p>
                <m>
                  c(v+w)=cv+cw
                </m> for all <m>c\in F</m> and <m>v, w\in V</m>.
                </p>
              </li>
              <li>
                <title>Distribution over scalar addition</title>
                <p>
                  <m>
                    (c+d)v=cv+dv
                  </m>
                  for all <m>c\in F</m> and <m>v, w\in V</m>.
                </p>
              </li>
              <li>
                <title>Scalar multiplication is associative</title>
                <p>
                <m>
                  c(dv)=(cd)v
                </m>
                for all <m>c,d\in F</m> and all <m>v\in V</m>.
                </p>
              </li>
              <li>
                <title>Scalar multiplication identity</title>
                <p>
                    <m>
                        1\,v=v
                      </m> for all <m>v\in V</m>.
                </p>
              </li>
            </ol>
          We call elements of the vector space <m>V</m> <term>vectors</term> and the elements of <m>F</m> <term>scalars</term>. 
          </p>
      </statement>
        </definition>
        <remark>
            <title>Arithmetic and existential axioms</title>
            <p>
                As with the axioms in <xref ref="d_field"/> we divide the vector space axioms into the <em>arithmetic axioms</em> (Axioms (i)-(ii),(v)-(vi),(vii)) and the <em>existential axioms</em> (Axioms (iii)-(iv)). 
            </p>
        </remark>
        <p>
            We now proceed to a litany of examples. Each one will be stated as a definition (for reference purposes) accompanied by a proof that the given structure does indeed constitute a vector space. 
            In a classic mathematical move, we begin with the simplest of all vector spaces, the <em>zero space</em>. Elementary as this example is, it serves well to illustrate the axiomatic nature of <xref ref="d_vector_space"/>. 
        </p>
          <definition xml:id="d_zero_space">
            <title>Zero space</title>
            <statement>
                <p>
                    Let <m>F</m> be a field, and let <m>V=\{\bot\}</m>, a set containing exactly one element. There is a unique <m>F</m>-vector space structure that can be given to <m>V</m>, defined as follows. 
                    <ul>
                        <li>
                            <title>Vector operations</title>
                            <p>
                                Vector addition on <m>V</m> is defined as <m>\bot+\bot=\bot</m>; scalar multiplication on <m>V</m> is defined as <m>c\cdot \bot=\bot</m> for all <m>c\in F</m>. 
                            </p>
                        </li>
                        <li>
                            <title>Zero vector</title>
                            <p>
                                The zero vector of <m>V</m> is <m>\bot</m>: <ie/>, <m>\boldzero=\bot</m>.
                            </p>
                        </li>
                        <li>
                            <title>Vector inverses</title>
                            <p>
                                The vector inverse of <m>\bot</m> is <m>\bot</m>: <ie/>, <m>-\bot=\bot</m>. 
                            </p>
                        </li>
                    </ul>
                    Since <m>\bot=\boldzero</m> with respect to this vector space structure, we have <m>V=\{\boldzero\}</m>. Accordingly, we call <m>V</m> a <term>zero space</term>. 
                </p>   
            </statement>
        </definition>
        <p>
            <xref ref="d_zero_space"/> makes two claims: that the given operations make <m>V=\{\bot\}</m> into a vector space, and that this is the <em>only</em> way to make <m>V=\{\bot\}</m> into a vector space. As with all claims in mathematics, these need to be proved, but as you will see, the proof is a very light affair. 
        </p>
        <proof>
            <title>Proof for <xref ref="d_zero_space"/></title>
            <p>
                Since <m>V=\{\bot\}</m> only has one item, there is no choice for what vector addition <m>V\times V\rightarrow V</m> and scalar multiplication <m>F\times V\rightarrow V</m> can be. They must be defined in the manner given in <xref ref="d_zero_space"/>. Similarly, we must have <m>\boldzero=\bot</m> and <m>-\bot=\bot</m>, as once again, <m>\bot</m> is the only element of <m>V</m>! This shows that there can be <em>at most</em> one way of giving <m>V</m> a vector space structure. 
            </p>
            <p>
                It is now easy to see that these choices do indeed satisfy the vector space axioms. That <m>\bot</m> satisfies the identity of <xref ref="eq_d_zero_vector">Axiom</xref> defining the zero vector <m>\boldzero</m> follows from the fact that 
                for all <m>v\in V</m> we have <m>v=\bot</m> (since <m>V=\{\bot\}</m>), and thus 
                    <md>
                        <mrow>\bot+v \amp =\bot+\bot</mrow>
                        <mrow> \amp = \bot</mrow>
                        <mrow> \amp =v</mrow>
                    </md>.
                    Thus <m>\bot=\boldzero</m> is the zero vector of the space. 
            </p>
            <p>
                Similarly, to show all elements of <m>V</m> have vector inverses amounts to showing that <m>\bot</m> has a vector inverse, since this is the only element of <m>V</m>. It is claimed that <m>-\bot=\bot</m> (<ie/>, <m>\bot</m> is its own vector inverse), which follows from the fact that 
                <md>
                    <mrow>-\bot+\bot \amp = \bot+\bot</mrow>
                    <mrow> \amp = \bot</mrow>
                    <mrow> \amp = \boldzero</mrow>
                </md>.
                Lastly, the identities of Axioms (i)-(ii) and (v)-(viii) in this setting all reduce to trivial statements of the form <m>\bot+\bot=\bot+\bot</m>. Consider Axiom (vii), for example. For all <m>v,w\in V</m>, we have <m>v=w=\bot</m>, in which case
                <md>
                    <mrow>c(v+w) \amp =c(\bot+\bot) </mrow>
                    <mrow> \amp =c\cdot \bot</mrow>
                    <mrow> \amp = \bot \amp \text{(def. of sc. mult.)}</mrow>
                </md> and 
                <md>
                    <mrow>cv+dw \amp =c\cdot \bot+d\cdot \bot</mrow>
                    <mrow> \amp = \bot+\bot</mrow>
                    <mrow> \amp =\bot</mrow>
                </md>.
                Thus 
                <me>
                    c(v+w)=\bot=cv+dw 
                </me>
                for all <m>v, w\in V</m> and <m>c\in F</m>. 
            </p>
            <p>
                We leave verification of the rest of the axioms to the reader. 
            </p>
        </proof>
    <p>
        It is worth formalizing the proof technique used above into an official procedure for showing whether something is a vector space. 
    </p>
    <algorithm xml:id="proc_vector_space">
        <title>Vector space verification</title>
        
        <statement>
            <p>
To decide whether a given set and operations is a vector space, proceed as follows. 
<ol>
  <li>
    <p>
      Make explicit the underlying set <m>V</m> of the proposed vector space.
    </p>
  </li>
  <li>
    <p>
      Make explicit what the scalar multiplication and vector addition operations are.
    </p>
  </li>
  <li>
    <p>
      Identify an element of <m>V</m> that serves as the zero vector (<ie/>, satisfies <xref ref="eq_zero_vector"/>) and for each <m>\boldv\in V</m> show that there is a vector <m>-\boldv</m> satisfying <xref ref="eq_vec_inv"/>.
    </p>
  </li>
  <li>
    <p>
      Show that the two vector operations and our choice of zero vector and vector inverses satisfy the axioms of <xref ref="d_vector_space"/>.
    </p>
  </li>
</ol>
</p>
    </statement>
    </algorithm>
<remark>
    <title>Vector space verification</title>
    <p>
        Think of steps (1)-(3) of <xref ref="proc_vector_space"/> as the issuing of official declarations about the makeup of our proposed vector space: <q>The underlying set shall be as stated</q>; <q>We declare the vector operations thusly</q>; <q>The zero vector shall be this element here, and vector inverses shall be assigned in this manner</q>. Step (4) is where we get down to the nitty gritty of showing that the proposed vector space structure articulated in (1)-(3) does indeed satisfy all the necessary properties.
</p>
<p>
In each of the remaining examples below we carefully lay out the details of items (1)-(3) while often leaving much of the work of item (4) to you. You will meet these vector spaces frequently throughout the rest of your life. Each time you do, it will be helpful for orientation purposes to mentally run through items (1)-(3). Ask yourself: What is the underlying set? What are vector operations? What acts as the zero vector, and how do I assign vector inverses?
    </p>
</remark>

<p>
  Having established this general quite general result, particular choices of the index set <m>I</m> now yield some very common vector spaces. 
</p>
<definition xml:id="d_ntuples">
  <title><m>n</m>-tuples</title>
  <statement>
    <p>
      Let <m>F</m> be a field. Given a positive integer <m>n</m>, recall that <m>F^n</m> is the set of all <m>F</m>-valued <m>n</m>-tuples: <ie/>, 
      <me>
        F^n=\{(a_1,a_2,\dots, a_n)\colon a_i\in F\}
      </me>.
      Below we define a vector space structure on <m>F^n</m>. 
      <ul>
        <li>
          <title>Vector operations</title>
          <p>
            Given <m>v=(a_1,a_2,\dots, a_n), w=(b_1,b_2,\dots, b_n)\in F^n</m> and <m>c\in \F</m>, we define 
            <md>
              <mrow>v+w \amp =(a_1+b_1,a_2+b_2,\cdots, a_n+b_n)</mrow>
              <mrow>cv \amp =(ca_1,ca_2,\dots, ca_n)</mrow>
            </md>.
          </p>
        </li>
        <li>
          <title>Zero vector</title>
          <p>
            The zero vector of <m>F^n</m> is <m>\boldzero=(0,0,\dots, 0)</m>. 
          </p>
        </li>
        <li>
          <title>Vector inverses</title>
          <p>
            Given a sequence <m>v=(a_1,a_2,\dots, a_n)\in F^n</m>, its vector inverse <m>-v</m> is 
            <me>
              -v=(-a_1,-a_2,\dots, -a_n)
            </me>.
          </p>
        </li>
      </ul>
    We call <m>F^n</m>, together with these vector operations, the <term>space of <m>F</m>-valued <m>n</m>-tuples</term> (or the <term>space of <m>n</m>-tuples with coordinates in <m>F</m></term>). 
    </p>
  </statement>
</definition>


<definition xml:id="d_infinite_sequences_space">
<title>Space of infinite sequences</title>
<statement>
<p>
  Let <m>F</m> be a field. Recall that <m>F^\infty</m> is the set of all <m>F</m>-valued infinite sequences: <ie/>, 
  <me>
    F^\infty=\{(a_i)_{i=1}^\infty\colon a_i\in F \text{ for all } i\in \Z_+\}
  </me>.
  Below we define a vector space structure on <m>F^\infty</m>.
  <ul>
    <li>
      <title>Vector operations</title>
      <p>
        Given <m>s=(a_i)_{i=1}^\infty, t=(b_i)_{i=1}^\infty\in F^\infty</m> and <m>c\in F</m>, we define 
        <md>
          <mrow>s+t\amp=(a_i+b_i)_{i=1}^\infty=(a_1+b_1, a_2+b_2,\dots) </mrow>
          <mrow>cs \amp =(ca_i)_{i=1}^\infty=(ca_1,ca_2,\dots) </mrow>
        </md>.
      </p>
    </li>
    <li>
      <title>Zero vector</title>
      <p>
        The zero vector of <m>F^\infty</m> with respect to these operations is 
        <me>
          \boldzero=(0)_{i=1}^\infty=(0,0,\dots)
        </me>.
      </p>
    </li>
    <li>
      <title>Vector inverses</title>
      <p>
        Given a sequence <m>s=(a_i)_{i=1}^\infty\in F^\infty</m>, its vector inverse is 
        <md>
          <mrow>-s \amp = (-a_i)_{i=1}^\infty=(-a_1,-a_2,\dots )</mrow>
        </md>.
      </p>
    </li>
  </ul>
</p>
</statement>
</definition>
<definition xml:id="d_matrix_space">
<title>Space of matrices</title>
<statement>
<p>
Let <m>F</m> be a field. Given positive integers <m>m,n\in\Z_+</m>, we define <m>F^{m,n}</m> to be the set of all <m>m\times n</m> matrices with entries in <m>F</m>: <ie/>, 
<me>
  F^{m,n}=\{\underset{m\times n}{A}=[a_{ij}]\colon a_{ij}\in F \text{ for all } (i,j)\in \{1,2\dots, m\}\times \{1,2,\dots, n\}\}
</me>.
Below we define a vector space structure on <m>F^{m,n}</m>. 
<ul>
  <title>Vector operations</title>
  <li>
    <p>
      Given matrices <m>A=[a_{ij}], B=[b_{ij}]\in F^{m,n}</m> and <m>c\in F</m>, we define 
      <md>
        <mrow>A+B \amp =[a_{ij}+b_{ij}]</mrow>
        <mrow>cA \amp =[ca_{ij}]</mrow>
      </md>.
    </p>
  </li>
  <li>
    <title>Zero vector</title>
    <p>
      The zero vector of <m>F^{m,n}</m> is the the zero matrix 
      <me>
        \boldzero=[0]_{\substack{1\leq i\leq m\\ 1\leq j\leq n}}
      </me>.
    </p>
  </li>
  <li>
    <title>Vector inverses</title>
    <p>
      Given a matrix <m>A=[a_{ij}]\in F^{m,n}</m> its vector inverse is
      <me>
        -A=[-a_{ij}]
      </me>.
    </p>
  </li>
</ul>
We call <m>F^{m,n}</m>, together with these vector operations, the <term>space of <m>m\times n</m> matrices with entries in <m>F</m></term> (or the <term>space of <m>F</m>-valued <m>m\times n</m> matrices</term>).

</p>
</statement>
</definition>
<p>
    Our next example, dealing as it does with tuples, represents a significant uptick in complexity and abstraction. This cost in abstraction ends up delivering a substantial payoff, however, as the more familiar examples that follow it can be seen as special cases. Recall that an <m>F</m>-valued tuple indexed by <m>I</m> is nothing more than a function <m>f\colon I\rightarrow F</m> that we conceptualize as a sequence of sorts using the notation <m>f=(f(i))_{i\in I}</m>. See <xref ref="ss_tuples_cart_prod" text="title"/> for details about tuples. 
</p>
<definition xml:id="d_tuple_space">
<title>Space of <m>F</m>-valued functions/tuples</title>
<statement>
<p>
Let <m>F</m> be a field. Given any set <m>I</m>, recall that <m>F^I</m> is defined as the set of all functions <m>f\colon I\rightarrow F</m>, or equivalently, the set of all <m>F</m>-valued tuples indexed by <m>I</m>: <ie/>, 
<me>
    F^I=\{f\colon I\rightarrow F\colon f \text{ a function}\}=\{(a_i)_{i\in I}\colon a_i\in F\}
</me>.
Below we define a vector space structure on <m>F^I</m>. 
<ul>
    <li>
        <title>Vector operations</title>
        <p>
            Given elements <m>f=(f(i))_{i\in I}, g=(g(i))_{i\in I}\in F^I</m> and scalar <m>c\in F</m>, we define 
            <md>
                <mrow>f+g \amp = (f(i)+g(i))_{i\in I}</mrow>
                <mrow>cf \amp =(cf(i))_{i\in I}</mrow>
            </md>.
            In other words, <m>f+g</m> is the function defined as <m>(f+g)(i)=f(i)+g(i)</m> for all <m>i\in I</m>, and <m>cf</m> is the function defined as <m>(cf)(i)=cf(i)</m> for all <m>i\in I</m>. 
        </p>
    </li>
    <li>
        <title>Zero vector</title>
        <p>
            The zero vector of <m>F^I</m> is the zero function <m>0_I\colon I\rightarrow F</m> defined as <m>0_I(i)=0</m> for all <m>i\in I</m>. In other words, using tuple notation, we have <m>\boldzero=0_I=(0)_{i\in I}</m>. 
        </p>
    </li>
    <li>
        <title>Vector inverses</title>
        <p>
            Given an element <m>f=(f(i))_{i\in I}\in F^I</m> its vector inverse <m>-f</m> is defined as 
            <me>
                -f=(-f(i))_{i\in I}
            </me>.
            In other words <m>-f</m> is the function on <m>I</m> defined as <m>(-f)(i)=-f(i)</m> for all <m>i\in I</m>.
        </p>
    </li>
</ul>
We call <m>F^I</m>, together with these vector operations, the <term>space of <m>F</m>-valued tuples indexed by <m>I</m></term>.
</p>
</statement>
</definition>
<theorem xml:id="th_vs_egs">
<title>Function spaces are vector spaces</title>
<statement>
<p>
Each set and accompanying vector operations in <xref first="d_ntuples" last="d_tuple_space"/> forms a vector space. 
</p>
</statement>
<proof>
    <p>
        We follow <xref ref="proc_vector_space"/>. The definition has taken care of steps (1)-(3) for us, it remains to show that the vector space axioms are satisfied. As you will see, the tuple notation for functions makes these proofs quite straightforward consequences of the field axioms satisfied by <m>F</m>.
        </p>
        <p> 
            Consider the arithmetic axioms first. We will verify that Axioms (i), (ii), and (v) are satisfied. Given <m>f=(f(i))_{i\in I},g=(g(i))_{i\in I},h=(h(i))_{i\in I}\in F^I</m> and <m>c\in F</m>, we have 
        <md>
            <mrow> f+g \amp = (f(i)+g(i))_{i\in I} \amp (\text{def. vec. add.}) </mrow>
            <mrow> \amp = (g(i)+f(i))_{i\in I} \amp (\text{field prop.})</mrow>
            <mrow> \amp = g+f \amp (\text{def. vec. add.})</mrow>
            <mrow>f+(g+h) \amp = (f(i)+(g+h)(i))_{i\in I} \amp (\text{def. vec. add.})</mrow>
            <mrow> \amp = (f(i)+(g(i)+h(i)))_{i\in I} \amp (\text{def. vec. add.})</mrow>
            <mrow> \amp = ((f(i)+g(i))+h(i))_{i\in I} \amp (\text{field prop.})</mrow>
            <mrow> \amp = ((f+g)(i)+h(i))_{i\in I} \amp  (\text{def. vec. add.})</mrow>
            <mrow> \amp = (f+g)+h \amp  (\text{def. vec. add.})</mrow>
            <mrow>c(f+g) \amp =(c(f+g)(i))_{i\in I} \amp (\text{def. scal. mult})</mrow>
            <mrow> \amp = (c(f(i)+g(i)))_{i\in I} \amp (\text{def. vec. add.})</mrow>
            <mrow> \amp = (cf(i)+cg(i))_{i\in I} \amp (\text{field prop.})</mrow>
            <mrow> \amp =((cf)(i)+(cg)(i))_{i\in I} \amp (\text{def. scal. mult})</mrow>
            <mrow> \amp = cf+cg \amp (\text{def. vec. add.})</mrow>
        </md>.
        Lastly we will show that <m>0_I</m> does indeed satisfy the additive identity axiom (Axiom (iii)), leaving the verification of Axiom (iv) to the reader. Given any element <m>f=(f(i))_{i\in I}\in F^I</m>, we have 
        <md>
            <mrow>0_I+f \amp =(0_I(i)+f(i))_{i\in I} \amp (\text{def. vec. add.})</mrow>
            <mrow> \amp = (0+f(i))_{i\in I}\amp (\text{def. of } 0_I)</mrow>
            <mrow> \amp = (f(i))_{i\in I} \amp (\text{field prop.})</mrow>
            <mrow> \amp = f</mrow>
        </md>,
        as desired. 
    </p>
</proof>
</theorem>


<example xml:id="eg_real_functions">
<title>Real-valued functions</title>
<statement>
<p>
Let <m>I=[a,b]\subseteq \R </m> be an interval in the real lines. Using the function interpretation <m>\R^{[a,b]</m> is the set of all functions of the form <m>f\colon [a,b]\rightarrow \R</m>. The vector operations defined in <xref ref="d_tuple_space"/> in this setting correspond to the function-arithmetic operations you met in precalculus and calculus: <ie/>, given functions <m>f,g\in \R^{[a,b]}</m>, their vector sum <m>f+g</m> is the function defined as 
<m>(f+g)(x)=f(x)+g(x)</m> for all <m>x\in [a,b]</m>. Similarly, given a scalar <m>c\in \R</m> and function <m>f\in \R^{[a,b]}</m>, the vector scalar multiple <m>cf</m> is the function defined as <m>(cf)(x)=cf(x)</m> for all <m>x\in \R</m>. 
</p>
</statement>
<solution>
<p>

</p>
</solution>
</example>

</subsection>
<subsection xml:id="">
<title>Vector space properties</title>
<theorem xml:id="th_zero_inv_unique">
<title>Uniqueness of zero vector and inverses</title>
<statement>
<p>
Let <m>V</m> be an <m>F</m>-vector space. 
<ol>
    <li>
        <p>
            The zero vector in <m>V</m> is unique: <ie/>, there is one and only one element of <m>V</m> that satisfies <xref ref="eq_zero_vector"/>.
        </p>
    </li>
    <li>
        <p>
            Inverse vectors are unique: <ie/>, for all <m>\boldv\in V</m> there is one and only one vector <m>-\boldv</m> satisfying <xref ref="eq_vec_inv"/>.
        </p>
    </li>
</ol>
</p>
</statement>
<proof>
<p>
</p>
</proof>
</theorem>



<theorem xml:id="th_vs_props">
<title>Vector space properties</title>
<statement>
<p>
Let <m>V</m> be an <m>F</m>-vector space. 
 <ol>
    <li>
        <p>
            For all <m>v\in V</m>, we have <m>0\boldv=\boldzero</m>.
        </p>
    </li>

    <li>
        <p>
            For all <m>c\in F</m>, we have <m>c\boldzero=\boldzero</m>.
        </p>
    </li>

    <li>
        <p>
            For all <m>v\in V</m>, we have <m>(-1)\boldv=-\boldv</m>.
        </p>
    </li>

    <li>
        <p>
            For all <m>v\in V</m> and <m>c\in \F</m>, if <m>cv=\boldzero</m>, then <m>c=0</m> or <m>v=\boldzero</m>.
        </p>
    </li>
</ol>
</p>
</statement>
<proof>
<p>
</p>
</proof>
</theorem>

</subsection>

</section>