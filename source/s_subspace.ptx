<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="s_subspace" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Subspaces</title>
    <introduction>
        <p>
      In this section we will study <xref ref="d_subspace" text="custom">subspaces</xref>, which are special subsets of vector spaces that <em>respect</em> the defining structure of a vector spaces: namely, the two vector operations. <xref ref="d_subspace"/> makes precise what we mean here by <sq>respect</sq>. 
    </p>
    <p>
      Subspaces arise naturally in any setting where vector spaces are at play, and are closely connected to solutions to linear systems. As we will see in <xref ref="th_subspace_vectorspace"/>, subspaces of vector spaces are vector spaces in their own right, furnishing us with yet more interesting examples of vector spaces. 
    </p>
    </introduction>
    <subsection xml:id="ss_subspace_def">
    <title>Definition and examples</title>
    <definition xml:id="d_subspace">
      <title>Subspace</title>
      <statement>
        <p>
          Let <m>V</m> be a vector space.
          A subset <m>W\subseteq V</m> is a
          <term>subspace</term> of <m>V</m> if the following conditions hold.
        <ol marker="(i)">
          <li xml:id="d_subspace_zero">
            <title><m>W</m> contains the zero vector</title>
            <p>
              <m>\boldzero\in W</m>.
            </p>
          </li>
          <li xml:id="d_subspace_add" >
            <title><m>W</m> is closed under addition</title>
            <p> For all <m> v_1, v_2\in V</m>, if <m> v_1, v_2\in W</m>, then <m> v_1+ v_2\in W</m>. Using logical shorthand:
            <me>
             v_1, v_2\in W\implies  v_1+ v_2\in W
            </me>.
          </p>
        </li>
        <li xml:id="d_subspace_mult">
          <title><m>W</m> is closed under scalar multiplication</title>
          <p> For all <m>c\in F</m> and <m> v\in V</m>, if <m> v\in W</m>, then <m>c v\in W</m>. Using logical shorthand:
          <me> v\in W\Rightarrow c v\in W</me>.
        </p>
      </li>
    </ol>
    </p>
  </statement>
</definition>
<example xml:id="eg_subspace_trivial">
<title>Trivial subspaces</title>
<statement>
<p>
Let <m>V</m> be an <m>F</m>-vector space. The following are subspaces of <m>V</m>: 
<ol>
  <li>
    <p>
      <m>W_1=\{\boldzero\}</m>
    </p>
  </li>
  <li>
    <p>
      <m>W_2=V</m>
    </p>
  </li>
</ol>
In other words, the set containing just the zero vector is a subspace of <m>V</m>, as is <m>V</m> itself. These are sometimes called the <em>trivial subspaces</em> of <m>V</m>. Observe that every subspace <m>W</m> lies between these two: <ie/>, we have  <m>\{\boldzero\}\subseteq W\subseteq V</m>. 
</p>
</statement>
<solution>
<p>
We prove that <m>W_1=\{\boldzero\}</m> is a subspace of <m>V</m>, leaving the proof for <m>W_2=V</m> to the reader. 
<ol marker="(i)">
  <li>
    <p>
      By definition, <m>\boldzero\in  W_1</m>. 
    </p>
  </li>
  <li>
    <p>
      Since <m>\boldzero</m> is the only element of <m>W_1</m> and since <m>\boldzero+\boldzero=\boldzero\in W_1</m>, we see that <m>W_1</m> is closed under addition. 
    </p>
  </li>
  <li>
    <p>
      Since <m>\boldzero</m> is the only element of <m>W_1</m>, we need only show that <m>c\boldzero\in W_1</m> for all scalars <m>c\in F</m>. But we have <m>c\boldzero=\boldzero</m> by <xref ref="th_vs_props"/>. Thus <m>c\boldzero\in W_1</m>, as desired. 
    </p>
  </li>
</ol> 
This proves <m>W_1=\{\boldzero\}</m> is a subspace of <m>V</m>. 
</p>
</solution>
</example>

<example>
  <statement>
    <p>
      Let <m>V=\R^2</m> and let
      <me>W=\{(t,t)\in\R^2 \colon t\in\R\}
      </me>.
      Prove that <m>W</m> is a subspace.
    </p>
  </statement>
  <solution>
    <p>
      We must show properties (i)-(iii) hold for <m>W</m>.
    <ol marker="i">
      <li>
        <p>
          The zero element of <m>V</m> is <m>\boldzero=(0,0)</m>,
          which is certainly of the form <m>(t,t)</m>.
          Thus <m>\boldzero\in W</m>.
        </p>
      </li>
      <li>
        <p>
          We must prove the implication <m> v_1,  v_2\in W\Rightarrow  v_1+ v_2\in W</m>.
          <md>
          <mrow> v_1, v_2\in W\amp \Rightarrow\amp   v_1=(t,t),  v_2=(s,s) \text{ for some \(t,s\in\R\) }</mrow>
          <mrow>\amp \Rightarrow\amp  v_1+ v_2=(t+s,t+s)</mrow>
          <mrow>\amp \Rightarrow\amp  v_1+ v_2\in W</mrow>
          </md>.
        </p>
      </li>
      <li>
        <p>
          We must prove the implication <m> v\in W\Rightarrow c v\in W</m>, for any <m>c\in \R</m>. We have
          <md>
          <mrow> v\in W\amp \Rightarrow\amp   v=(t,t)</mrow>
          <mrow>\amp \Rightarrow\amp  c v=(ct,ct)</mrow>
          <mrow>\amp \Rightarrow\amp  c v\in W</mrow>
          </md>
        </p>
      </li>
    </ol>
    </p>
  </solution>
</example>
<example>
  <statement>
    <p>
      Let <m>V=\R^n</m> and let
      <me>
      W=\{(x,y)\in \R^2\colon x, y\geq 0\}
      </me>.
      Is <m>W</m> a vector space? Decide which of the of properties (i)-(iii) in <xref ref="d_subspace"/> (if any) are satisfied by <m>W</m>.
    </p>
  </statement>
  <solution>
    <p>
      <ol marker="i">
      <li>
        <p>
          Clearly <m>\boldzero=(0,0)\in W</m>.
        </p>
      </li>
      <li>
        <p>
          Suppose <m> v_1=(x_1,y_1),  v_2=(x_2,y_2)\in W</m>. Then <m>x_1, x_2, y_1, y_2\geq 0</m>, in which case <m>x_1+x_2, y_1+y_2\geq 0</m>, and hence <m> v_1+ v_2\in W</m>. Thus <m>W</m> is closed under addition.
        </p>
      </li>
      <li>
        <p>
          The set <m>W</m> is <em>not</em> closed under scalar multiplication. Indeed, let <m> v=(1,1)\in W</m>. Then <m>(-2) v=(-2,-2)\notin W</m>.
        </p>
      </li>
    </ol>
    </p>
    
  </solution>
</example>
<p>
  As we now endeavor to show, if <m>W</m> is a subspace of a vector space <m>V</m>, then it <em>inherits</em> a vector space structure from <m>V</m> by simply  <em>restricting</em> the vector operations defined on <m>V</m> to the subset <m>W</m>.
</p>

<theorem xml:id="th_subspace_vectorspace">
  <title>Subspaces are vector spaces</title>
  <statement>
    <p>
    Let <m>W</m> be a subspace of the vector space <m>V</m>. 
    <ol>
      <li>
        <p>
          The vector operations of <m>V</m> restrict to operations on <m>W</m> that satisfy the vector space axioms. 
        </p>
      </li>
      <li>
        <p>
          The zero vector of <m>W</m>, considered as a vector space, is the zero vector of <m>V</m>. 
        </p>
      </li>
      <li>
        <p>
          Given an element <m>\boldw\in W</m>, its vector inverse with respect to the vector space structure of <m>W</m> is equal to its vector inverse with respect to the vector space structure of <m>V</m>.  
        </p>
      </li>
    </ol>
  </p>
</statement>
<proof>
    <p>
    It is important to understand how <xref first="d_subspace_zero" last="d_subspace_mult">Axioms</xref> of <xref ref="d_subspace"/> come into play here. Without them we would not be able to say that restricting the vector operations of <m>V</m> to elements of <m>W</m> actually gives rise to well-defined operations on <m>W</m>. To be well-defined the operations must output elements that lie not just in <m>V</m>, but in <m>W</m> itself. This is precisely what being closed under addition and scalar multiplication guarantees. In more detail, since <m>\boldw_1+\boldw_2\in W</m> for all <m>w_1,w_2\in W</m> (Axiom (ii)), the vector addition on <m>V</m> gives rise by restriction to a well-defined operation on <m>W</m>; similarly, since <m>c\boldw\in W</m> for all <m>c\in \R</m> and <m>\boldw\in W</m>, the scalar multiplication operation on <m>V</m> gives rise by restriction to a well-defined scalar multiplication on <m>W</m>. 
  </p>
  <p>
    Once we know restriction gives rise to well-defined operations on <m>W</m>, verifying the <m>arithmetic axioms</m> of  <xref ref="d_vector_space"/> amounts simply to observing that if a condition is true for all <m>v</m> in <m>V</m>, it is certainly true for all <m> v</m> in the subset <m>W</m>.
  </p>
  <p>
    The <q>existential axioms</q> (iii) and (iv) of <xref ref="d_vector_space"/>, however, require special consideration. By definition, a subspace <m>W</m> contains the zero vector of <m>V</m>, and clearly this still acts as the zero vector when we restrict the vector operations to <m>W</m>. What about vector inverses? We know that for any <m> v\in W</m> there is a vector inverse <m>- v</m> lying somewhere in <m>V</m>. We must show that in fact <m>- v</m> lies in <m>W</m>: <ie /> we need to show that the operation of taking the vector inverse is well-defined on <m>W</m>. We prove this as follows:
    <md>
    <mrow> v\in W \amp\implies (-1) v\in W \amp (<xref ref="d_subspace"/>, \text{(iii) } )</mrow>
    <mrow> \amp\implies - v\in W \amp (<xref ref="th_vs_props"/>, (iii)) </mrow>
    </md>.
  </p>
</proof>
</theorem>
<p>
  Before moving on to more examples of subspaces, we provide a procedure for determining whether something is a subspace. Note that the procedure merges the verification of Axioms (ii)-(iii) of <xref ref="d_subspace"/> into a single step, using the notion of a <em>linear combination</em>. Now is a good time to make this notion official. 
</p>
<definition xml:id="d_linear_comb">
<title>Linear combination</title>
<statement>
<p>
Let <m>V</m> be an <m>F</m>-vector space, and let <m>v_1,v_2,\dots, v_n</m> be a collection of vectors of <m>V</m>. A <term>linear combination</term> of the vectors <m>v_i</m> is a vector expression of the form 
<men xml:id="eq_lin_comb">
  c_1v_1+c_2v_2+\cdots +c_nv_n
</men>,
where <m>c_i\in F</m> for all <m>1\leq i\leq n</m>. The scalars <m>c_i</m> are called the <term>coefficients</term> of the linear combination. The linear combination <xref ref="eq_lin_comb"/> is <term>trivial</term> if <m>c_i=0</m> for all <m>1\leq i\leq n</m>, and <term>nontrivial</term> if <m>c_i\ne 0</m> for some <m>1\leq i\leq n</m>. A vector <m>v</m> is a <term>linear combination of the <m>v_i</m></term> if we have 
<me>
  v=c_1v_1+c_2v_2+\cdots +c_nv_n
</me>
for some choice of scalars <m>c_i\in F</m>. 
</p>
</statement>
</definition>

<algorithm xml:id="proc_subspace">
  <title>Two-step proof for subspaces</title>
  <statement>
    <p>
      We can merge conditions (ii)-(iii) of <xref ref="d_subspace"/> into a single statement about linear combinations, deriving the following two-step method for proving that a set <m>W</m> is a subspace of a vector space <m>V</m>.
    <ol>
      <li xml:id="proc_subspace_zero">
        <p>
          Show <m>\boldzero\in W</m>
        </p>
      </li>
      <li xml:id="proc_subspace_ops">
        <p>
          Show that
          <me>
           v_1,  v_2\in W\implies c v_1+d v_2\in W
          </me>,
          for all <m>c,d\in F</m>.
        </p>
      </li>
    </ol>
    </p>
  </statement>
</algorithm>
<p>
  <xref ref="th_matrix_null_space"/> below serves both as an illustration of <xref ref="proc_subspace"/> and a rich source of examples of subspaces. It tells us that the solutions to a matrix equation <m>A\boldx=\boldzero</m> constitutes a subspace of <m>\F^n</m>. This set is called the <em>null space</em> of the matrix. (We will postpone an official definition of null space until we introduce linear transformations.) 
</p>
<p>
  The statement and proof of <xref ref="th_matrix_null_space"/> will make use of matrix multiplication and elementary properties that matrix multiplication satisfies. The usual definition of matrix multiplication (for real matrices) generalizes directly to an arbitrary field, and as such we will not include an official definition. Furthermore, all the usual matrix multiplication properties you know and love over the reals carry over to the more general setting of matrices over a general field <m>F</m>. We will take this for granted and not include an official statement of those properties.  
</p>
<p>
  Lastly, we include another fiat that facilitates dealing with so-called <em>column vectors</em> <m>\boldx\in F^{n,1}</m>.
</p>
<assumption xml:id="fiat_col_vecs_tuples">
<title>Tuples shall be column vectors, and vice versa</title>
  <statement>
    <p>
      We hereby declare that all <m>n</m>-tuples <m>(a_1,a_2,\dots, a_n)\in \F^n</m> shall be equated with the corresponding column vector in <m>F^{n,1}</m>: <ie/>, 
      <me>
      (a_1,a_2,\dots, a_n)
      =
      \begin{bmatrix} 
      a_1\\ a_2\\ \vdots \\ a_n
      \end{bmatrix}
      </me>
      in <m>\F^{n,1}</m>.
    </p>
  </statement>
</assumption>
<theorem xml:id="th_matrix_null_space">
<title>Matrix null space</title>
<statement>
<p>
Let <m>A\in F^{m,n}</m>. The set 
<me>
  W=\{\boldx\in F^n \colon \underset{m\times n}{A}\, \underset{n\times 1}{\boldx}=\underset{m\times 1}{\boldzero}\}
</me>
of solutions to the matrix equation <m>A\boldx=\boldzero</m> is a subspace of <m>\F^n</m>. 
</p>
</statement>
<proof>
<p>
  We follow <xref ref="proc_subspace"/>. 
  <ol marker="(i)">
    <li>
      <p>
        Note that according to <xref ref="fiat_col_vecs_tuples"/>, we have <m>\boldzero=(0,0,\dots, 0)=\underset{n\times 1}{\boldzero}</m>, and thus  
        <me>
          A\boldzero=A\underset{n\times 1}{\boldzero}=\underset{m\times 1}{\boldzero}
        </me>.
        This proves that <m>\boldzero\in W</m>.
      </p>
    </li>
    <li>
      <p>
        We want to show that if <m>\boldx_1,\boldx_2\in W</m>, then so is <m>c\boldx_1+d\boldx_2</m> for any <m>c,d\in F</m>, 
      </p>
      <p>
        Assume <m>\boldx_1,\boldx_2\in W</m>. By definition this means <m>A\boldx_1=A\boldx_2=\underset{m\times 1}{\boldzero}</m>. But then we have 
        <md>
          <mrow>A(c\boldx_1+d\boldx_2) \amp = cA\boldx_1+dA\boldx_2 \amp (\text{matrix props.})</mrow>
          <mrow> \amp = c\underset{m\times 1}{\boldzero}+d\underset{m\times 1}{\boldzero}</mrow>
          <mrow> \amp = \underset{m\times 1}{\boldzero}</mrow>
        </md>,
        showing that <m>c\boldx_1+d\boldx_2\in W</m>, as desired. 
      </p>
    </li>
  </ol>
</p>
</proof>
</theorem>
<example xml:id="eg_subspace_hyperplane">
<title>Hyperplanes of <m>\R^n</m></title>
<statement>
<p>
A <em>hyperplane</em> of <m>\R^n</m> is a set <m>H\subseteq \R^n</m> defined as the set of solutions to a linear equation of the form 
      <men xml:id="eq_rm_hyperplane">
        a_1x_1+a_2x_2+\cdots +a_nx_n=b
      </men>,
      where <m>a_i,b\in \R</m> and <m>a_i\ne 0</m> for some <m>i</m>. (In other words <m>H</m> is the set of solutions to a <em>nontrivial</em> linear equation with coefficients in <m>\R</m>.)
      <ol>
        <li>
          <p>
            Prove that if <m>b\ne 0</m>, then <m>H</m> is not a subspace of <m>\R^n</m>. 
          </p>
        </li>
        <li>
          <p>
            Prove that if <m>b=0</m>, then <m>H</m> is a subspace of <m>\R^n</m>. 
          </p>
        </li>
      </ol>
</p>
</statement>
<solution>
<p>
<ol>
  <li>
    <p>
      If <m>b\ne 0</m>, then clearly <m>\boldzero=(0,0,\dots, 0)\notin H</m>, since 
      <me>
        a_10+a_20+\cdots +a_n0=0\ne b
      </me>.
      It follows that <m>H</m> is not a subspace in this case, since it fails Axiom (i). 
    </p>
  </li>
  <li>
    <p>
      Assume <m>b=0</m>. Let 
      <me>
        A=\begin{bmatrix}
      a_1 \amp a_2 \amp \cdots \amp a_n
      \end{bmatrix}
      </me>,
      the <m>1\times n</m> matrix consisting of the coefficients of the linear equation. We have 
      <me>
        H=\{\boldx\in \R^n\colon  A\boldx=[0]\}
      </me>.
      Thus <m>H</m> is a subspace by <xref ref="th_matrix_null_space"/>. 
    </p>
  </li>
</ol>
</p>
</solution>
</example>

</subsection>
<subsection xml:id="ss_function_spaces">
<title>Important function subspaces</title>
<definition xml:id="d_polynomials">
<title>Polynomials</title>
<statement>
<p>
Assume <m>F\in \{\R,\C\}</m>, and let <m>I</m> be an infinite subset of <m>F</m>. A <term>polynomial function on <m>I</m></term> is a function <m>f\colon I\rightarrow F</m> that can be written in the form 
<men xml:id="eq_poly">
  f(x)=a_nx^n+a_{n-1}x+\cdots +a_1x+a_0
</men>,
for some nonnegative integer <m>n</m> and scalars <m>a_k\in F</m>. Given <m>f</m> as in <xref ref="eq_poly"/>, <m>a_k</m> is called the <m>k</m>-th <term>coefficient</term> of <m>f</m>; furthermore, if <m>a_n\ne 0</m>, we call <m>a_nx^n</m> the <term>leading term</term> of <m>f</m>, and we  if <m>a_n\ne 0</m>, and we define the <term>degree</term> of <m>f</m>, denoted <m>\deg f</m> to be <m>n</m>.
</p>
<p>
  Given a nonnegative integer <m>n</m>, we define <m>P_n(I)</m> to be the set of all polynomial functions on <m>I</m> of degree at most <m>n</m>: <ie/>, 
  <me>
    P_n(I)=\{f\in F^I\colon f(x)=a_nx^n+a_{n-1}x^{n-1}+\cdots +a_1x+a_0 \text{ for some } a_i\in F\}
  </me>.
  Lastly we define <m>P(I)</m> to be the set of all polynomial functions on <m>I</m>. Since any polynomial on <m>I</m> is of the form <m>f(x)=\anpoly</m> for some <m>n\in \Z_{\geq 0}</m>,  we have 
  <me>
    P(I)=\bigcup_{n=0}^\infty P_n(I)
  </me>.
</p>
</statement>
</definition>
<theorem xml:id="th_polynomial_space">
<title>Polynomial spaces</title>
<statement>
<p>
Let <m>F\in \{\R, \C\}</m>, and let <m>I</m> be an infinite subset of <m>F</m>.
<ol>
  <li>
    <p>
      <m>P(I)</m> is a subspace of <m>F^I</m>. 
    </p>
  </li>
   <li>
     <p>
     <m>P_n(I)</m> is a subspace of <m>F^I</m> for all <m>n\in \Z_{\geq 0}</m>. 
    </p>
  </li>
</ol>
</p>
</statement>
<proof>
<p>
</p>
</proof>
</theorem>
<p>
  Although not necessary for the proof of <xref ref="th_polynomial_space"/>, the result below will be useful to us for future discussions. In short, it says that the coefficients of a polynomial uniquely determine it (as long as the domain <m>I</m> is infinite). 
</p>
<theorem xml:id="th_poly_equality">
<title>Polynomial equality</title>
<statement>
<p>
Let <m>F\in \{\R, \C\}</m> and let <m>I</m> be an infinite subset of <m>F</m>.
<ol>
  <li>
    <p>
      Given <m>f(x)=\anpoly\in P_n(I)</m>, we have 
      <me>
        f=\boldzero\iff a_k=0 \text{ for all } 1\leq k\leq n
      </me>.
    </p>
  </li>
  <li>
    <p>
      Given <m>f(x)=\anpoly\in P_n(I)</m> and <m>g(x)=\bmpoly\in P_m(I)</m> with <m>a_n\ne 0</m> and <m>b_m\ne 0</m>, we have 
      <me>
        f=g \iff n=m \text{ and } a_k=b_k \text{ for all } 1\leq k\leq n
      </me>.
    </p>
  </li>
</ol>
</p>
</statement>
<proof>
<p>
</p>
</proof>
</theorem>
<definition xml:id="d_function_subspaces">
<title>Function subspaces over <m>\R</m></title>
<statement>
<p>
Let <m>I</m> be an interval of <m>\R</m> that contains at least two elements. 
<ol>
  <li>
    <p>
      We denote by <m>C(I)</m> the set of all continuous functions on <m>I</m>: i.e.,
    <me>
      C(I)=\{f\in \R^I\colon f \text{ is continuous on }I\}
    </me>.
    </p>
  </li>

  <li>
    <p>
      Fix <m>n\geq 1</m>.
      A function <m>f\colon I\rightarrow \R</m> is <m>C^{n}</m> on <m>I</m> if <m>f</m> is <m>n</m>-times differentiable on <m>I</m> and its <m>n</m>-th derivative <m>f^{(n)}(x)</m> is continuous.
      The set of all <m>C^{n}</m> functions on <m>I</m> is denoted <m>C^{n}(I)</m>.
    </p>
  </li>

  <li>
    <p>
      A function <m>f\colon I\rightarrow \R</m> is <m>C^{\infty}</m> on I if <m>f</m> is infinitely differentiable on <m>I</m>.
      The set of all <m>C^{\infty}</m> functions on <m>I</m> is denoted <m>C^{\infty}(I)</m>.
    </p>
  </li>
</ol>
</p>
</statement>
</definition>
<theorem xml:id="th_function_spaces">
  <title>Function subspaces.</title>
  <statement>
    <p>
      Let <m>I\subseteq \R</m> be a an interval containing at least two elements. 
      The sets <m>C(I)</m>, <m>C^{n}(I)</m>, <m>C^{\infty}(I)</m>, <m>P(I)</m>, <m>P_{n}(I)</m> are all subspaces of <m>\R^I</m>, and we have the following chain of subspaces:
    <me>
      P_{n}(I)\subseteq P(I)\subseteq C^{\infty}(I)\subseteq C^{n}(I)\subseteq C(I)\subseteq \R^{I}
    </me>.
    </p>
  </statement>
</theorem>
</subsection>

</section>