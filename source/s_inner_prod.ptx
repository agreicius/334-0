<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="s_inner_prod" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Inner product spaces</title>
    <introduction>
    <p>
      An <em>inner product</em> is an additional layer of structure we can define on an <m>\R</m>- or <m>\C</m>-vector space <m>V</m> that generalizes the dot product operation on <m>\R^n</m>, familiar to students of multivariable calculus at least in the <m>n=2</m> or <m>n=3</m> cases. As with the definition of vector spaces, <xref ref="d_inner_prod"/> proceeds axiomatically. Think of those axioms as a list of important properties, all enjoyed by the familiar dot product operation, that we want our generalized version of the dot product to satisfy. 
    </p>
    <p>
      The addition of an inner product enriches the structure of a vector space considerably, and gives rise to a number of additional useful analytic tools. We highlight a few below.
      <dl>
        <li>
          <title>Distance and angle</title>
          <p>
            A notion of <em>distance</em> and <em>angle</em> between two vectors can be defined relative to a given inner product. These provide a numeric measurement of how <q>close</q> (distance) or <q>closely oriented</q> (angle) two vectors in our space are.
          </p>
        </li>
        <li>
          <title>Orthogonality</title>
          <p>
          Two vectors <m>\boldv, \boldw\in V</m> are <em>orthogonal</em>, relative to a given inner product, if <m>\langle \boldv, \boldw\rangle=0</m>. Orthogonality leads further to a general notion of <em>orthogonal projection</em> onto a subspace <m>W\subseteq V</m>.
          </p>
        </li>
        <li>
          <title>Orthogonal bases</title>
          <p>
          An <em>orthogonal basis</em> of a vector space <m>V</m>, relative to a given inner product, is one whose elements are pairwise orthogonal. As we will see there are many computational advantages of working with an orthogonal basis.
          </p>
        </li>
      </dl>
    </p>
  </introduction>
<subsection xml:id="ss_inner_product">
<title>Inner product</title>
<p>
    Technically, we will deal with two distinct notions of inner product in this course: one for <m>\R</m>-vector spaces, and one for <m>\C</m>-spaces. It turns out, however, that the notion of a complex inner product is an extension of sorts of the real inner product. As such, the definition below rolls both concepts up into one formulation. In order to cover the more general complex inner product, it makes use of the complex conjugation and complex modulus operations 
    <md>
        <mrow>\overline{\phantom{v}}\colon \C \amp \rightarrow \C \amp \abs{\phantom{v}}\colon \C\amp \rightarrow \C</mrow>
        <mrow>z=a+bi \amp \longmapsto \overline{z}=a-bi \amp z=a+bi\amp \longmapsto \abs{z}=\sqrt{a^2+b^2}</mrow>
    </md>.
    It is useful to recall how these operations behave with respect to real numbers, thinking as always of <m>\R</m> as a subset of <m>\C</m>: namely, given <m>a=a+0i\in \R</m>, we have <m>\overline{a}=a</m>, and the complex modulus of <m>a</m> is equal to the real absolute value of <m>a</m>, since <m>\sqrt{a^2+0^2}=\sqrt{a^2}=\abs{a}</m>. 
</p>
<definition xml:id="d_inner_prod">
<title>Inner product</title>
<statement>
<p>
Let <m>F\in \{\R, \C\}</m>. An <term>inner product</term> on an <m>F</m>-vector space <m>V</m> is a function 
<md>
    <mrow>\angvec{\phantom{v}, \phantom{v}}\colon V\times V \amp \rightarrow F</mrow>
    <mrow>(v,w) \amp \longmapsto \angvec{v,w}</mrow>
</md>
that satisfies the following properties. 
<ol marker="(i)">
    <li>
        <title>Conjugate symmetry</title>
        <p>
            <men xml:id="eq_inner_conj_symm">\angvec{w,v}=\overline{\angvec{v,w}}</men> for all <m>v,w\in V</m>. 
        </p>
    </li>
    <li>
        <title>Additivity</title>
        <p>
            <mdn>
                <mrow xml:id="eq_inner_add_left">\angvec{v_1+v_2,w}\amp=\angvec{v_1,w}+\angvec{v_2,w} </mrow>
                <mrow xml:id="eq_inner_add_right"> \angvec{v,w_1+w_2}\amp =\angvec{v,w_1}+\angvec{v,w_2} </mrow>
            </mdn>
            for all <m>v,v_1,v_2,w,w_1,w_2\in V</m>. 
        </p>
    </li>
    <li>
        <title>(Conjugate) homogeneity</title>
        <p>
            <mdn>
                <mrow xml:id="eq_inner_homog_left">\angvec{cv,w} \amp = c\angvec{v,w}</mrow>
                <mrow xml:id="eq_inner_homog_right">\angvec{v,cw} \amp =\overline{c}\angvec{v,w}</mrow>
            </mdn>
            for all <m>v,w\in V</m> and <m>c\in F</m>.
        </p>
    </li>
    <li>
        <title>Positivity</title>
        <p>
           
           <md>
            <mrow>\angvec{v,v} \amp \geq 0, \text{ and } </mrow>
            <mrow>\angvec{v,v} \amp =0\iff v=\boldzero </mrow>
           </md>
           for all <m>v\in V</m>.
        </p>
    </li>
</ol>
An <term>inner product space</term> is a pair <m>(V,\angvec{ \, , })</m>, where <m>V</m> is an <m>F</m>-vector space (<m>F\in \{\R,\C\}</m>) and <m>\angvec{ \,  , }</m> is an inner product on <m>V</m>. 
</p>
</statement>
</definition>
<remark>
    <title>Inner product</title>
    <p>
        The conjugate symmetry property <xref ref="eq_inner_conj_symm"/> implies that the property <xref ref="eq_inner_add_right"/> follows from <xref ref="eq_inner_add_left"/>, and that the property <xref ref="eq_inner_homog_right"/> follows from <xref ref="eq_inner_homog_left"/>. As such, we have indulged in some redundancy in <xref ref="d_inner_prod"/>. 
    </p>
</remark>
<remark>
    <title>Inner product: real case</title>
    <p>
        Note that when <m>F=\R</m>, <xref ref="eq_inner_conj_symm"/> reduces to <m>\angvec{w,z}=\angvec{v,w}</m>, since <m>\angvec{v,w}\in \R</m> implies <m>\overline{\angvec{v,w}}=\angvec{v,w}</m>. Similarly, the homogeneity properties reduce to 
        <me>
            \angvec{cv,w}=\angvec{v,cw}=c\angvec{v,w}
        </me>,
        since <m>c\in \R</m> implies <m>\overline{c}=c</m>. 
    </p>
</remark>
<p>
    We give a short list of some common inner product spaces, starting from the most familiar, and moving to the more exotic. We state each example as a definition, but of course in each instance it must be proved that the given vector space and operation <m>\angvec{\, , }</m> satisfies the inner product axioms. We will leave that verification to the reader for the most part, restricting our comments in each case only to the positivity axiom.  
</p>
<definition xml:id="d_dot">
<title>Dot product</title>
            <statement>
                <p>
                    Let <m>F\in \{\R,\C\}</m>.  The function <m>\angvec{\, ,}\colon F^n\times F^n\rightarrow F</m>  defined as 
                    <men xml:id="eq_dot">
                        \angvec{(x_1,x_2,\dots, x_n),(y_1,y_2,\dots, y_n)}=\sum_{i=1}^n x_i\overline{y_i}
                    </men>
                    is an inner product. When <m>F=\R</m> this is called the <term>dot product</term>; when <m>F=\C</m> this is called the <term>complex dot product</term> or <term>standard Hermitian inner product</term>. 
                </p>
            </statement>
          </definition>
<definition xml:id="d_weighted_dot">
<title>Weighted dot product</title>
            <statement>
                <p>
                    Let <m>F\in \{\R,\C\}</m>.  Given positive real numbers <m>k_1, k_2, \dots , k_n</m>, the function <m>\angvec{\, ,}\colon F^n\times F^n\rightarrow F</m>  defined as 
                    <men xml:id="eq_weighted_dot">
                        \angvec{(x_1,x_2,\dots, x_n),(y_1,y_2,\dots, y_n)}=\sum_{i=1}^nk_ix_i\overline{y_i}
                    </men>
                    is an inner product on <m>F^n</m> called the 
                    <term>weighted dot product</term> with weights <m>(k_1,k_2,\dots, k_n)</m>.
                </p>
            </statement>
          </definition>
<definition xml:id="d_poly_eval">
<title>Polynomial evaluation</title>
<statement>
<p>
Let <m>F\in \{\R, \C\}</m>, and let <m>n</m> be a positive integer. Given any distinct scalars <m>c_1,c_2,\dots, c_{n+1}\in F</m>, the function 
<md>
    <mrow>\angvec{\phantom{v},\phantom{v}}\colon P_n(F)\times P_n(F) \amp \rightarrow F</mrow>
    <mrow>(f,g) \amp \mapsto \angvec{f,g}=\sum_{i=1}^{n+1}f(c_i)\overline{g(c_i)}</mrow>
</md>
is an inner product on <m>P_n(F)</m> . We call <m>\angvec{\, ,}</m> a <term>polynomial evaluation inner product</term>. 
</p>
</statement>
</definition>
<definition xml:id="d_integral_inner">
<title>Integral inner product</title>
<statement>
<p>
Let <m>I=[a,b]</m> be a closed interval in <m>\R</m>. The function 
<md>
    <mrow>\angvec{\phantom{v},\phantom{v}}\colon C^\infty(I)\times C^{\infty}(I) \amp \rightarrow \R</mrow>
    <mrow>(f,g) \amp \mapsto \angvec{f,g}=\int_{a}^b f(x)g(x)\, dx</mrow>
</md>
is an inner product on <m>C^\infty(I)</m>. We call <m>\angvec{\, , }</m> an <term>integral inner product</term>. 
</p>
</statement>
</definition>
<convention>
    <title>Inner product</title>
    <p>
        Since the definition of inner product assumes that the base field is either <m>\R</m> or <m>\C</m>, henceforth anytime the inner product is in play for an <m>F</m>-vector space <m>V</m>, it should be assumed that <m>F\in \{\R,\C\}</m>. 
    </p>
</convention>
<theorem xml:id="th_inner_prod">
<title>Inner product properties</title>
<statement>
<p>
Let <m>(V,\angvec{\, ,})</m> be an inner product space. 
<ol>
    <li>
        <p>
            Given <m>w_0\in V</m>, the function <m>T\colon V\rightarrow F</m> defined as 
            <me>
                T(v)=\angvec{v,w_0}
            </me>
            is a linear transformation.
        </p>
    </li>
    <li>
        <p>
            <m>\angvec{w,\boldzero}=\angvec{\boldzero,w}=0</m> for all <m>w\in V</m>.
        </p>
    </li>
    <li>
        <p>
            Let <m>v\in V</m>. The following statements are equivalent. 
            <ol>
                <li>
                    <p>
                        <m>v=\boldzero</m>. 
                    </p>
                </li>
                <li>
                    <p>
                        <m>\angvec{v,w}=0</m> for all <m>w\in V</m>. 
                    </p>
                </li>
                <li>
                    <p>
                        <m>\angvec{v,v}=0</m>.
                    </p>
                </li>
            </ol>
        </p>
    </li>
</ol>
</p>
</statement>
<proof>
<p>
</p>
</proof>
</theorem>

</subsection>
<subsection xml:id="ss_norm">
<title>Norm</title>
<definition xml:id="d_norm">
<title>Norm</title>
<statement>
<p>
Let <m>(V,\angvec{\, ,})</m> be an inner product space. The function <m>\norm{\phantom{v}}\colon V\rightarrow F</m> defined as 
<me>
    \norm{v}=\sqrt{\angvec{v,v}}
</me>
is called the <term>norm</term> associated to <m>\angvec{\, , }</m>. 
</p>
</statement>
</definition>
<p>
    Observe that the norm function defined above is dependent on the inner product. That is, each choice of inner product for a vector space <m>V</m> gives rise to its own norm function. We illustrate this with the inner products introduced above. 
</p>
<example xml:id="eg_norms">
<title>Norm</title>
<statement>
<p>
<ol>
    <li>
        <title>Weighted dot product</title>
        <p>
            Consider the weighted dot product on <m>F^n</m> with weights <m>k_1,k_2,\dots, k_n</m>. Given <m>\boldx=(x_1,x_2,\dots, x_n)\in F^n</m>, we have 
            <md>
                <mrow>\norm{\boldx} \amp = \sqrt{\angvec{\boldx,\boldx}} \amp (\text{def. of norm}) </mrow>
                <mrow> \amp = \sqrt{\sum_{i=1}^nk_ix_i\overline{x_i}}</mrow>
                <mrow> \amp = \sqrt{\sum_{i=1}^n k_i\abs{x_i}^2} \amp (z\overline{z}=\abs{z}^2)</mrow>
            </md>.
        </p>
    </li>
    <li>
        <title>Polynomial evaluation</title>
        <p>
           Consider a polynomial evaluation inner product on <m>P_n(F)</m> with distinct inputs <m>c_1,c_2,\dots, c_{n+1}</m>. Given <m>f\in P_n(F)</m>, we have 
           <md>
            <mrow>\norm{f} \amp =\sqrt{\angvec{f,f}} \amp (\text{def. of norm}) </mrow>
            <mrow> \amp =\sqrt{\sum_{i=1}^{n=1}f(c_i)\overline{f(c_i)}}</mrow>
            <mrow> \amp =\sqrt{\sum_{i=1}^{n=1}\abs{f(c_i)}^2} \amp (z\overline{z}=\abs{z}^2)</mrow>
           </md> 
        </p>
    </li>
    <li>
        <title>Integral inner product</title>
        <p>
            Consider the integral inner product on <m>C(I)</m>, where <m>I=[a,b]</m> is a closed interval in <m>\R</m>. Given <m>f\in C^(I)</m>, we have 
            <md>
                <mrow>\norm{f} \amp =\sqrt{\angvec{f,f}} \amp (\text{def. of norm})</mrow>
                <mrow> \amp = \sqrt{\int_a^b f(x)f(x)\, dx}</mrow>
                <mrow> \amp = \sqrt{\int_a^b f^2(x)\, dx}</mrow>
            </md>.
        </p>
    </li>
</ol>
</p>
</statement>
</example>
<theorem xml:id="th_cauchy-schwarz">
<title>Cauchy-Schwarz inequality</title>
<statement>
<p>
Let <m>(V,\angvec{\, ,})</m> be an inner product space. We have 
<men xml:id="eq_cauchy-schwarz">
    \abs{\angvec{v,w}}\leq \norm{v}\norm{w}
</men>
for all <m>v,w\in V</m>. Furthermore, the inequality <xref ref="eq_cauchy-schwarz"/> is an equality if and only if one of <m>v</m> or <m>w</m> is a scalar multiple of the other.
</p>
</statement>
<proof>
<p>
    First observe that inequality <xref ref="eq_cauchy-schwarz"/> clearly holds if <m>w=\boldzero</m>, since in this case we have <m>\abs{\angvec{v,w}}=\norm{v}\norm{w}=0</m>.
</p>
<p>
    We now show <xref ref="eq_cauchy-schwarz"/> holds when <m>w\ne \boldzero</m>.   For any scalar <m>c\in F</m>, we have 
    <men xml:id="eq_C-S_proof_ineq1">
        \angvec{v+cw,v+cw} \geq 0
    </men>. 
    Let's unpack this inequality using additional properties of the inner product:
    <md>
        <mrow>\angvec{v+cw,v+cw} \amp \geq 0</mrow>
        <mrow>\angvec{v,v}+\angvec{cv,w}+\angvec{v,cw}+\angvec{cw,cw} \amp \geq 0</mrow>
        <mrow> \angvec{v,v}+c\angvec{w,v}+\overline{c}\angvec{v,w}+c\overline{c}\angvec{w,w} \amp \geq 0 </mrow>
        <mrow>\norm{v}^2+c\overline{\angvec{v,w}}+\overline{c}\angvec{v,w}+\abs{c}^2\norm{w}^2 \amp \geq 0 </mrow>
    </md>.
    Assume <m>w\ne \boldzero</m>. Since the last inequality is true for <em>any</em> scalar <m>c\in F</m>, it is true for the particular choice choice <m>c=-\frac{\angvec{v,w}}{\norm{w}^2}</m>. (Note that <m>c</m> is well defined since <m>w\ne \boldzero</m>, and hence <m>\norm{w}\ne 0</m>.) We now substitute this expression in for <m>c</m> and do some further simplification: 
    <md>
        <mrow> \norm{v}^2-\frac{\angvec{v,w}}{\norm{w}^2}\cdot\overline{\angvec{v,w}}-\frac{\overline{\angvec{v,w}}}{\norm{w}^2}\cdot\angvec{v,w}+\frac{\abs{\angvec{v,w}}^2}{\norm{w}^4}\cdot\norm{w}^2 \amp \geq 0  </mrow>
        <mrow>\norm{v}^2-\frac{\abs{\angvec{v,w}}^2}{\norm{w}^2}- \cancel{\frac{\abs{\angvec{v,w}}^2}{\norm{w}^2}}+\cancel{\frac{\abs{\angvec{v,w}}^2}{\norm{w}^2}}\amp \geq 0 </mrow>
        <mrow>\abs{\angvec{v,w}}^2  \leq \norm{v}^2\norm{w}^2\amp</mrow>
    </md>.
    Taking square-roots of both sides (and using the fact that <m>\sqrt{a^2}=a</m> for all <em>nonnegative</em> real numbers <m>a</m>), we conclude that 
    <me>
        \abs{\angvec{v,w}}\leq \norm{v}\norm{w}
    </me>,
    as desired.    
</p>
<p>
    Having proved that <xref ref="eq_cauchy-schwarz"/> holds for all <m>v,w\in V</m>, we now show that we have equality if and only one of the vectors is a scalar multiple of the other. The reverse implication is easy to see: if <m>v=cw</m>, for example, then we have 
    <md>
        <mrow>\abs{\angvec{v,w}} \amp = \abs{\angvec{cw,w}}=\abs{c}\norm{w}^2 </mrow>
        <mrow>\norm{v}\norm{w} \amp =\norm{cw}\norm{w}=\abs{c}\norm{w}^2</mrow>
    </md>,
    showing that equality holds in <xref ref="eq_cauchy-schwarz"/>. The argument in the case <m>w=cv</m> is very similar. (We <q>cheated</q> somewhat above, using property (2) of <xref ref="th_norm"/>. However, the proof of that property does not use Cauchy-Schwarz, so we are not indulging in circularity here.) 
</p>
<p>
    It remains only to show the forward implication. Assume <m>\abs{\angvec{v,w}}=\norm{v}\norm{w}</m>; we will show that one of the vectors is a scalar multiple of the other. If <m>w=\boldzero</m>, then the claim follows trivially, since <m>w=0v</m>. If <m>w\ne \boldzero</m>, then working our way backward through the various simplifications starting with <xref ref="eq_C-S_proof_ineq1"/>, we see that 
    <md>
        <mrow> \abs{\angvec{v,w}}=\norm{v}\norm{w}=0 \amp \iff \abs{\angvec{v,w}}^2=\norm{v}^2\norm{w}^2 </mrow>
        <mrow> \amp\iff \angvec{v+cw,v+cw}=0, \hspace{10pt} c=-\frac{\angvec{v,w}}{\norm{w}^2} </mrow>
        <mrow> \amp \implies v+cw=\boldzero, \hspace{10pt} c=-\frac{\angvec{v,w}}{\norm{w}^2}</mrow>
        <mrow> \amp \iff v=-cw, \hspace{10pt} c=-\frac{\angvec{v,w}}{\norm{w}^2}</mrow>
    </md>,
    where the last line follows from (3) of <xref ref="th_inner_prod"/>. Thus, one of the vectors (namely, <m>v</m>) is scalar multiple of the others in this case, as desired. 

</p>
</proof>
</theorem>
<theorem xml:id="th_norm">
<title>Norm properties</title>
<statement>
<p>
Let <m>(V,\angvec{\, ,})</m> be an inner product space. 
<ol>
    <li>
        <p>
            <m>\norm{v}=0</m> if and only if <m>v=\boldzero</m> for all <m>v\in V</m>. 
        </p>
    </li>
    <li>
        <p>
            <m>\norm{cv}=\abs{c}\norm{v}</m> for all <m>v\in V</m> and <m>c\in F</m>. 
        </p>
    </li>
    <li>
        <title>Triangle inequality</title>
        <p>
            <m>\norm{v+w}\leq \norm{v}+\norm{w}</m> for all <m>v,w\in V</m>. 
        </p>
    </li>
    <li>
        <title>Parallelogram law</title>
        <p>
            <m>\norm{v+w}^2+\norm{v-w}^2=2\norm{v}^2+2\norm{w}^2</m>
        </p>
    </li>

</ol>
</p>
</statement>
<proof>
<p>
</p>
</proof>
</theorem>
<remark>
    <title>Norm functions</title>
    <p>
        You can use the first three statements of <xref ref="th_norm"/> to axiomatize the properties of a norm. That is given a <m>F</m>-vector space <m>V</m> (with <m>F\in \{\R, \C\}</m>), a norm on <m>V</m> is a function <m>\norm{\phantom{v}}\colon V\rightarrow \R</m> satisfying the following axioms.
        <ol marker="(i)">
            <li>
                <p>
                    <m>\norm{v}\geq 0</m> for all <m>v\in V</m>, and moreover, <m>\norm{v}=0</m> if and only if <m>v=\boldzero</m>. 
                </p>
            </li>
            <li>
                <p>
                    <m>\norm{cv}=\abs{c}\norm{v}</m> for all <m>v\in V</m> and <m>c\in F</m>. 
                </p>
            </li>
            <li>
                <p>
                    <m>\norm{v+w}\leq \norm{v}+\norm{w}</m> for all <m>v,w\in V</m>. 
                </p>
            </li>
        </ol>
        In this sense, the norm we have defined is just one special case of a norm function: one arising from a given inner product. It is not the case that all norms arise in this manner: for example, you can show that the <q>taxicab distance</q> on <m>\R^n</m> defined as  
        <me>
            \norm{(x_1,x_2,\dots, x_n)}=\sum_{i=1}^n\abs{x_i}
        </me>
        is a norm, but does not arise from an inner product. In fact, you can show that a norm (in the axiomatic sense) arises from an inner product if and only it satisfies the parallelogram law. 
    
    </p>
</remark>
<remark>
<title>Distance function</title>
<p>
Let <m>(V,\angvec{\, ,})</m> be an inner product space. The norm function, which we understand as a measure of size or length of vectors, gives rise in turn to a <em>distance function</em> 
<me>
    d(v,w)=\norm{v-w}
</me>
that can be thought of as measure of the distance between vectors.  From <xref ref="th_norm"/> it follows easily that the function <m>d\colon V\times V\rightarrow \R</m> satisfies the following properties.
        <ol marker="(i)">
            <li>
                <p>
                    <m>d(v,w)\geq 0</m> for all <m>v,w\in V</m>, and moreover, we have <m>d(v,w)=0</m> if and only if <m>v=w</m>.  
                </p>
            </li>
            <li>
                <p>
                    <m>d(v,w)\leq d(v,v')+d(v',w)</m> for all <m>v,w, v'\in V</m>. 
                </p>
            </li>
        </ol> 
This distance function <m>d</m> provides yet another layer of structure to an inner product space, making it what is known as a <em>metric space</em>. Metric spaces come equipped with their own rich theory that includes useful and familiar concepts from calculus (and analysis) like limits, continuity, closed and open sets. connected and compact sets, <etc/>. 
</p>
</remark>

</subsection>
</section>