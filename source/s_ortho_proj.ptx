<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="s_ortho_proj" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Orthogonal projection</title>
    <introduction>
    <p>
      A trick we learn early on in physics-- specifically, in dynamics problems in <m>\R^2</m>-- is to pick a convenient axis and then decompose any relevant vectors (force, acceleration, velocity, position, <etc />) into a sum of two components: one that points along the chosen axis, and one that points perpendicularly to it. As we will see in this section, this technique can be vastly generalized. Namely, instead of <m>\R^2</m> we  can take any inner product space <m>(V, \langle\, , \rangle)</m>; and instead of a chosen axis in <m>\R^2</m>, we can choose any finite-dimensional subspace <m>W\subseteq V</m>; then any <m>v\in V</m> can be decomposed in the form
    <me>
      v=w+w^\perp,
    </me>
    where <m>w\in W</m> and <m>w^\perp</m> is a vector <em>orthogonal</em> to <m>W</m>, in a sense we will make precise below. Just as in our toy physics example, this manner of decomposing vectors helps simplify computations in problems where the subspace <m>W</m> chosen is of central importance.
  </p>
  </introduction>
    <subsection xml:id="ss_ortho_comp">
  <title>Orthogonal complement</title>
  <definition xml:id="d_ortho_comp">
  <title>Orthogonal complement</title>
  <statement>
  <p>
  Let <m>(V,\angvec{\, ,})</m> be an inner product space. Given a subspace <m>W\subseteq V</m>, its <term>orthogonal complement</term> <m>W^\perp</m> is the set of all vectors of <m>v</m> that are orthogonal to every vector in <m>W</m>: <ie/>, 
  <men xml:id="eq_ortho_comp">
    W^\perp=\{v\in V\colon \angvec{v,w}=0 \text{ for all } w\in W\}
  </men>.
  </p>
  </statement>
  </definition>
  <p>
    The next theorem tells us that to check <m>w\in W^\perp</m>, it suffices to check that <m>w</m> is orthogonal to the elements of a spanning set of <m>W</m>.
  </p>
  <theorem xml:id="th_ortho_comp_span">
  <title>Orthogonality and spanning sets</title>
  <statement>
  <p>
  Let <m>(V,\angvec{\, , })</m> be an inner product space, and let <m>W=\Span (w_i)_{i\in I}</m>. We have <m>v\in W^\perp</m> if and only if <m>\angvec{v,w_i}=0</m> for all <m>i\in I</m>: <ie/>, 
    <me>
        W^\perp=\{v\in V\colon \angvec{v,w_i}=0 \text{ for all } i\in I\}
    </me>.
  </p>
  </statement>
  <proof>
  <p>
    The forward implication follows purely from logic. Conversely, assume that <m>\angvec{v,w_i}=0</m> for all <m>i\in I</m>. Given <m>w\in W</m>, we can write <m>w=\sum_{i\in J}c_{i}v_{i}</m>  for some finite subset <m>J\subseteq I</m>, in which case 
    <md>
        <mrow>\angvec{v,w} \amp =\sum_{i\in J}\overline{c_i}\angvec{v,\sum_{i\in J}c_iw_i}</mrow>
        <mrow> \amp =\sum_{i\in J}\overline{c_i}\angvec{v,w_i}</mrow>
        <mrow> \amp =\sum_{i\in J}\overline{c_i}\cdot 0</mrow>
        <mrow> \amp = 0</mrow>
    </md>.
    Thus <m>v\in W^\perp</m>. 
  </p>
  </proof>
  </theorem>
  <p>
    <xref ref="th_ortho_comp_span"/> is especially useful for computing <m>W^\perp</m> when <m>W</m> admits a finite basis or spanning set. 
  </p>
  <example xml:id="eg_ortho_comp_line">
    <statement>
      <p>
        Consider the inner product space <m>\R^2</m> together with the dot product. Let <m>W=\Span\left((1,1)\right)=\{(t,t)\colon t\in \R\}</m>: the line <m>\ell\subseteq \R^2</m> with equation <m>y=x</m>. Compute <m>W^\perp</m> and identify it as a familiar geometric object in <m>\R^2</m>.
      </p>
    </statement>
    <solution>
      <p>
        According to <xref ref="th_ortho_comp_span"/>, since <m>W=\Span((1,1))</m>, we have
        <me>
          \boldx\in W^\perp \iff \boldx\cdot (1,1)=0
        </me>.
        Letting <m>\boldx=(x,y)</m>, we see that <m>\boldx\cdot (1,1)=0</m> if and only if <m>x+y=0</m>, if and only if <m>y=-x</m>. Thus <m>W^\perp=\{(x,y)\colon y=-x\}</m> is the line <m>\ell'\subseteq \R^2</m> with equation <m>y=-x</m>. Observe that the lines <m>\ell</m> and <m>\ell'</m> are indeed perpendicular to one another. (Graph them!)
      </p>
    </solution>
  </example>
  <example xml:id="eg_ortho_comp_plane">
    <statement>
      <p>
        Consider the inner product space <m>\R^3</m> together with the dot product. Let <m>W\subseteq \R^3</m> be the plane with equation <m>x-2y-z=0</m>.  Compute <m>W^\perp</m> and identify this as a familiar geometric object in <m>\R^3</m>.
      </p>
    </statement>
    <solution>
      <p>
        First, solving <m>x-2y-z=0</m> for <m>(x,y,z)</m>, we see that
        <me>
          W=\{(2s+t,s,t)\colon s,t\in \R\}=\Span\left((2,1,0),(1,0,1)\right)
        </me>.
        Next, according to <xref ref="th_ortho_comp_span"/> we have
        <me>
          \boldx\in W^\perp\iff \boldx\cdot (2,1,0)=0 \text{ and } \boldx\cdot (1,0,1)=0
        </me>.
       It follows that <m>W^\perp</m> is the set of vectors <m>\boldx=(x,y,z)</m> satisfying the linear system
       <me>
         \begin{linsys}{3}
         2x\amp +\amp y \amp \amp  \amp = \amp 0\\
         x\amp \amp  \amp +\amp z \amp = \amp 0
       \end{linsys}.
       </me>
       Solving this system using Gaussian elimination we conclude that
       <me>
       W^\perp=\{(t,-2t,-t)\colon t\in \R\}=\Span\left((1,-2,-1)\right)
       </me>,
       which we recognize as the line <m>\ell\subseteq \R^3</m> passing through the origin with direction vector <m>(1,-2,-1)</m>. This is none other than the normal line to the plane <m>W</m> passing through the origin.
      </p>
    </solution>
  </example>
  <theorem xml:id="th_ortho_comp">
  <title>Orthogonal complement</title>
  <statement>
  <p>
  Let <m>W</m> be a subspace of the inner product space  <m>(V,\angvec{\, ,})</m>. 
  <ol>
    <li>
        <p>
            <m>W^\perp</m> is a subspace of <m>V</m>. 
        </p>
    </li>
    <li>
        <p>
            <m>W\cap W^\perp=\{\boldzero\}</m>.
        </p>
    </li>
    <li>
        <p>
            <m>W\subseteq (W^\perp)^\perp</m>.
        </p>
    </li>
    <li>
        <title><m>W</m> finite dimensional</title>
        <p>
            If <m>W</m> is finite dimensional, then 
            <mdn>
                <mrow xml:id="eq_ortho_comp_decomp">V \amp= W\oplus W^\perp </mrow>
            </mdn>.
            Furthermore, we have 
            <men xml:id="eq_ortho_comp_self_dual">
                (W^\perp)^\perp=W
            </men>
            in this setting.             
        </p>
    </li>
  </ol>
  </p>
  </statement>
  <proof>
  <p>
    <ol>
      <li>
        <p>
          We use the 2-step technique. 
        </p>
        <p>
          Since <m>\angvec{\boldzero,v}=0</m> for all <m>v\in V</m>, it is certainly true that 
          <m>\angvec{\boldzero,w}=0</m> for all <m>w\in W</m>. Thus <m>\boldzero\in W^\perp</m>.
        </p>
      </li>
      <li>
        <p>
          Assume <m>v_1,v_2\in W^\perp</m>. By definition this means 
          <me>
            \angvec{v_1,w}=\angvec{v_2,w}=0
          </me>
          for all <m>w\in W</m>. It follows that for any <m>c,d\in F</m>, and for all <m>w\in W</m> we have 
          <md>
            <mrow>\angvec{cv_1+dv_2,w} \amp = c\angvec{v_1,w}+d\angvec{v_2,w}</mrow>
            <mrow> \amp =c\cdot 0+d\cdot 0</mrow>
            <mrow> \amp =0</mrow>
          </md>,
          and thus that <m>cv_1+dv_2\in W^\perp</m>. 
        </p>
      </li>
      <li>
        <p>
          Assume <m>v\in W\cap W^\perp</m>. Since <m>v\in W</m> and <m>v\in W^\perp</m>, we must have <m>\angvec{v,v}=0</m>. The positivity axiom for inner products then implies that <m>v=\boldzero</m>. Thus <m>W\cap W^\perp=\{\boldzero\}</m>. 
        </p>
      </li>
      <li>
        <p>
          Let <m>w\in W</m>. Given any <m>v\in W^\perp</m>, we have 
          <md>
            <mrow>\angvec{w,v} \amp =\overline{\angvec{v,w}}=\overline{0}=0</mrow>
          </md>.
          Thus <m>\angvec{w,v}=0</m> for all <m>v\in W^\perp</m>, showing that <m>w\in (W^\perp)^\perp</m>. This proves <m>W\subseteq (W^\perp)^\perp</m>. 
        </p>
      </li>
      <li>
        <p>
          Assume <m>W</m> is finite dimensional. By definition this means <m>W</m> has a finite basis. The Gram-Schmidt procedure then guarantees that we can produce an orthogonal basis <m>B=(w_1,w_2,\dots, w_r)</m> of <m>W</m>. Furthermore, the proof of the validity of the Gram-Schmidt procedure shows that for any <m>v\in V</m> the vector 
          <me>
            w^\perp=v-\sum_{i=1}^r\frac{\angvec{v,w_i}}{\angvec{w_i,w_i}}w_i
          </me>
          is orthogonal to <m>w_i</m> for all <m>1\leq i\leq r</m>. Since <m>W=\Span ((w_1,w_2,\dots, w_n))</m>, we conclude from <xref ref="th_ortho_comp_span"/> that <m>w^\perp\in W^perp</m>. Noting that 
          <me>
            w=\sum_{i=1}^r\frac{\angvec{v,w_i}}{\angvec{w_i,w_i}}w_i\in W
          </me>,
          we see that for all <m>v\in V</m> we can write 
          <me>
            v=w+w^\perp
          </me>,
          where <m>w\in W</m> and <m>w^\perp\in W^\perp</m>. This proves that <m>V=W+W^\perp</m>. Since <m>W\cap W^\perp=\{\boldzero\}</m> by (2), we conclude that <m>V=W\oplus W^\perp</m>. 
        </p>
        <p>
          Lastly, we show in this case that <m>W=(W^\perp)^\perp</m>. Using (3) above, it suffices to show <m>(W^\perp)^\perp\subseteq W</m>. Take <m>v\in (W^\perp)^\perp</m>, and write <m>v=w+w^\perp</m>, where <m>w\in W</m> and <m>w^\perp\in W</m>. Since <m>v\in (W^\perp)^\perp</m>, we have
          <md>
            <mrow>0 \amp =\angvec{v,w^\perp}</mrow>
            <mrow> \amp =\angvec{w+w^\perp,w^\perp}</mrow>
            <mrow> \amp =\angvec{w,w^\perp}+\angvec{w^\perp,w^\perp}</mrow>
            <mrow> \amp =0+\angvec{w^\perp,w^\perp}</mrow>
            <mrow> \amp = \angvec{w^\perp,w^\perp}</mrow>
          </md>.
          Since <m>\angvec{w^\perp,w^\perp}=0</m>, we conclude that <m>w^\perp=\boldzero</m>, and hence that 
          <me>
            v=w+w^\perp=w+\boldzero=w\in W
          </me>,
          as desired.
        </p>
      </li>
    </ol>
  </p>
  </proof>
  </theorem>
  
  </subsection>
  <subsection xml:id="ss_ortho_proj">
  <title>Orthogonal projection</title>
  <definition xml:id="d_ortho_proj">
  <title>Orthogonal projection</title>
  <statement>
  <p>
  Let <m>(V, \langle\, , \rangle)</m> be an inner product space, and let <m>W</m> be a finite-dimensional subspace of <m>V</m>.
Since <m>V=W\oplus W^{\perp}</m>, given any <m>v\in V</m> there is a unique choice of <m>w\in W</m> and <m>w^{\perp}\in W^{\perp}</m> satisfying
<men xml:id="eq_ortho_decomp">
    v=w+w^{\perp}.
</men>
The vectors <m>w</m> and <m>w^{\perp}</m> are the <term>orthogonal projections</term> of <m>v</m> onto <m>W</m> and <m>W^{\perp}</m>, respectively, and are denoted <m>w=\proj_W(v)</m> and <m>w^{\perp}=\proj_{W^\perp}(v)</m>.
In this manner the direct sum decomposition <m>V=W\oplus W^{\perp}</m> gives rise to functions
<md>
    <mrow>\proj_W\colon V \amp \rightarrow V \amp \proj_{W^\perp}\colon V\amp \rightarrow V</mrow>
</md>
called <term>orthogonal projection</term> onto <m>W</m> and <m>W^\perp</m>, respectively. 
  </p>
  </statement>
  </definition>
  <p>
    From the proof of <xref ref="th_ortho_comp"/> we extract the following procedure for computing <m>\proj_W(v)</m> for a finite-dimensional subspace of an inner product space. 
  </p>
  <algorithm xml:id="proc_ortho_proj">
    <title>Orthogonal projection</title>
    <statement>
      <p>
        Let <m>W</m> be a finite-dimensional subspace of the inner product space <m>(V,\angvec{\, ,})</m>. To compute <m>\proj_W</m> and <m>\proj_{W^\perp}</m>, proceed as follows. 
        <ol>
          <li>
            <p>
              Compute an orthogonal basis <m>B=(v_1,v_2,\dots, v_r)</m> of <m>W</m> using the Gram-Schmidt procedure. 
            </p>
          </li>
          <li>
            <p>
              Given <m>v\in V</m>, we have 
              <mdn>
                <mrow xml:id="eq_ortho_proj_formula">\proj_W(v) \amp =\sum_{i=1}^r\frac{\angvec{v,w_i}}{\angvec{w_i,w_i}}w_i</mrow>
                <mrow xml:id="eq_ortho_proj_comp_formula">\proj_{W^\perp} \amp = v-\proj_W(v)</mrow>
              </mdn>.
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </algorithm>
  <theorem xml:id="th_ortho_proj">
  <title>Orthogonal projection</title>
  <statement>
  <p>
  Let <m>(V, \langle\, , \rangle)</m> be an inner product space, and let <m>W</m> be a finite-dimensional subspace of <m>V</m>.
<ol>
    <li>
      <title>Orthogonal projection is linear</title>
      
      
        <p>
            <m>\operatorname{proj}_{W}, \operatorname{proj}_{W^\perp}\in \mathcal{L}(V)</m>.
        </p>
    </li>

    <li>
      <title>Closest element of <m>W</m></title>
        <p>
            <m>\proj_W(v)</m> is the unique element of <m>W</m> satisfying the following property:
        <men xml:id="eq_ortho_proj_closest">
            d(v,\proj_W(v))\leq d(v,w) \text{ for all } w\in W
        </men>.
        In other words, <m>\proj_W(v)</m> is the unique element in <m>W</m> that is closest to <m>v</m>. 
        </p>
    </li>
</ol>
  </p>
  </statement>
  <proof>
  <p>
  </p>
  </proof>
  </theorem>
  <definition xml:id="d_distance_subspace">
  <title>Distance to subspace</title>
  <statement>
  <p>
  Let <m>W</m> be a subspace of the inner product space <m>(V,\angvec{\, ,})</m>. Given a vector <m>v\in V</m>, its <term>distance</term> to <m>W</m>, denoted <m>d(v,W)</m>, is defined as 
  <me>
    d(v,W)=\inf\{d(v,w)\colon w\in W\}
  </me>.
  </p>
  </statement>
  </definition>
  <corollary xml:id="cor_ortho_proj">
    <title>Distance to <m>W</m></title>
    <statement>
      <p>
        Let <m>W</m> be a finite-dimensional subspace of the inner product space <m>(V,\angvec{\, ,})</m>. For all <m>v\in V</m>, we have 
        <men xml:id="eq_dist_v_W">
          d(v,W)=d(v,\proj_W(v))=\norm{v-\proj_W(v)}
        </men>.
      </p>
    </statement>
  </corollary>
  </subsection>

</section>