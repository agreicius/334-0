<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="s_span_ind" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Span and linear independence</title>
    <introduction>
        <p>
      There are many situations in mathematics where we want to describe an infinite set in a concise and useful manner. A guiding example of this for us is the parametric description of infinite sets of solutions to systems of linear equations that you learn about in a first course in linear algebra. We would like to develop an analogous technique for describing general vector spaces and their subspaces. 
    </p>
    <p>
    As we will see in the next section the relevant linear algebraic tool for this purpose is the concept of a <em>basis</em>. Loosely speaking, a basis for a vector space <m>V</m> is a set of vectors that is large enough to <em>generate</em> the entire space, and small enough to contain <em>no redundancies</em>. What exactly we mean by <q>generate</q> is captured by the rigorous notion of <em>span</em>; and what we mean by <q>no redundancies</q> is captured by <em>linear independence</em>.
    </p>
    </introduction>
    <subsection xml:id="ss_span">
    <title>Span</title>
    <p>
        In a nutshell we will define the span of a tuple <m>(v_i)_{i\in I}</m> of vectors to be the set of all linear combinations of those vectors. Since we allow the index set <m>I</m> of a tuple to be arbitrary (and possibly infinite), we need to first make proper sense of what a linear combination of <m>(v_i)_{i\in I}</m> is. We do so with the following somewhat technical definition. 
    </p>
    <definition xml:id="d_lin_comb_tuple">
    <title>Linear combination of a tuple</title>
    <statement>
    <p>
    Let <m>V</m> be an <m>F</m>-vector space, and let <m>(v_i)_{i\in I}</m> be a tuple of elements of <m>V</m> where <m>I</m> is nonempty. A <term>linear combination</term> of the vectors <m>v_i</m> is an expression of the form 
    <men xml:id="eq_lin_comb_tuple">
        \sum_{i\in I}c_iv_i
    </men>,
    where <m>c_i\in I</m> for all <m>i</m>, and <m>c_i=0</m> for all but finitely many <m>i\in I</m>. 
    </p>
    <p>
      If <m>c_i=0</m> for all <m>i\in I</m>, we call the linear combination <xref ref="eq_lin_comb_tuple"/> the <term>trivial linear combination</term> and define 
      <me>
        \boldzero=\sum_{i\in I}0v_i
      </me>.
      Otherwise, letting <m>c_{i_1},c_{i_2},\dots, c_{i_n}</m> be the finitely many nonzero coefficients, we define 
        <me>
            \sum_{i\in I}c_iv_i=\sum_{k=1}^nc_{i_k}v_k=c_{i_1}v_{i_1}+c_{i_2}v_{i_2}+\cdots+c_{i_n}v_{i_n}
        </me>.
    </p>
    </statement>
    </definition>
    <remark>
    <title>Linear combination of tuples</title>
    <p>
        For the most part we will be dealing with <m>n</m>-tuples of vectors, where the index set <m>I=\{1,2,\dots, n\}</m>. In this special case, the <q>for all but finitely many</q> condition is automatic, making <xref ref="d_lin_comb_tuple"/> very straightforward: a linear combination of a tuple <m>(v_1,v_2,\dots, v_n)</m> is just a vector of the form 
        <me>
            c_1v_1+c_2v_2+\cdots +c_nv_n
        </me>,
        where <m>c_i\in F</m>.
    </p>
    </remark>
    <p>
        We now proceed to the definition of the <em>span</em> of a tuple <m>S=(v_i)_{i\in I}</m> of vectors. The definition is broken into two cases depending on whether <m>S=()</m> is the empty tuple (a list with no elements). 
    </p>
    <definition xml:id="d_span">
    <title>Span</title>
    <statement>
    <p>
    Let <m>V</m> be an <m>F</m>-vector space, and let <m>S=(v_i)_{i\in I}</m> be a tuple of vectors of <m>V</m>, where <m>I</m> is a nonempty set. The <term>span</term> of <m>(v_i)_{i\in I}</m>, denoted <m>\Span (v_i)_{i\in I}</m>, is defined as follows. 
    <ul>
        <li>
            <p>
                If <m>I=\emptyset</m>, and consequently <m>S=()</m> is the empty tuple (or empty list), then we define
                <men xml:id="eq_span_empty">
                    \Span S=\Span()=\{\boldzero\}
                </men>.
            </p>
        </li>
        <li>
            <p>
                If <m>I\ne \emptyset</m>, then we define <m>\Span(v_i)_{i\in I}</m> as  the set of all linear combinations of <m>(v_i)_{i\in I}</m>: <ie/>, 
    <men xml:id="eq_span">
     \Span (v_i)_{i\in I}=\{v\in V\colon v=\sum_{k=1}^nc_{i_k}v_{i_k} \text{ for some } n\in \Z_+, c_{i_k}\in F\}  
    </men>.
            </p>
        </li>
    </ul>
    </p>
    </statement>
    </definition>
    <remark xml:id="rm_span">
        <p>
        Let <m>(v_i)_{i\in I}</m> be tuple of vectors in <m>V</m>. 
        <ol>
          <li>
            <p>
              The zero vector is always an element of <m>\Span(v_i)_{i\in I}</m>. We treat the cases where <m>I</m> is empty or nonempty separately.
            </p>
            <p>
                If <m>I=\emptyset</m>, then <m>(v_i)_{i\in I}=()</m> is the empty tuple and <m>\Span S=\{\boldzero\}</m> by definition. 
            </p>
            <p>
                If <m>I\ne \emptyset</m>, then we can always express <m>\boldzero</m> as the trivial linear combination <m>\boldzero=\sum_{i\in I}0v_i</m>. Thus <m>\boldzero\in \Span(v_i)_{i\in I}</m>. 
            </p>
          </li>
          <li>
              <p>
                The set <m>\{v_i\colon i\in I\}</m> is contained in <m>\Span(v_i)_{i\in I}</m>. Indeed, given any <m>i\in I</m>, we have <m>v_i=1v_i\in \Span(v_i)_{i\in I}</m>.
              </p>
          </li>

          <li>
            <p>
              For a tuple <m>(v)</m> of length 1, we have <m>\Span(v)=\{cv\colon c\in F\}</m>, the set of all scalar multiples of <m>v</m>. 
            </p>
          </li>
        </ol>
        </p>
      </remark>
    <example xml:id="eg_span_2space">
      <title>Examples in <m>\R^2</m></title>
      <statement>
        <p>
        Let <m>V=\R^2</m>. For each tuple <m>S=(v_i)_{i\in I}</m>, identify <m>\Span(v_i)_{i\in I}</m> as a familiar geometric object.
        <ol>
          <li>
            <p>
              <m>S=()</m>
            </p>
          </li>
          <li>
            <p>
              <m>S=(\boldzero)</m>
            </p>
          </li>
          <li>
            <p>
              <m>S=((a,b))</m>, <m>(a,b)\ne (0,0)</m>
            </p>
          </li>
          <li>
            <p>
              <m>S=((1,0),(0,1))</m>
            </p>
          </li>
          <li>
            <p>
              <m>S=((1,1),(2,2))</m>
            </p>
          </li>
          <li>
            <p>
              <m>S=((1,1),(1,2))</m>
            </p>
          </li>
          <li>
            <p>
              <m>S=((a,b))_{(a,b)\in \R^2}</m>
            </p>
          </li>
        </ol>
        </p>
      </statement>
      <solution>
        <p>
        <ol>
          <li>
            <p>
              <m>\Span()=\{(0,0)\}</m>, the set containing just the origin, by definition.
            </p>
          </li>
          <li>
            <p>
              <m>\Span(\boldzero)</m> is the set of all scalar multiples of <m>\boldzero</m>. Thus <m>\Span(\boldzero)=\{\boldzero\}</m>, the set containing just the origin.
            </p>
          </li>
          <li>
            <p>
              <m>\Span((a,b))</m> is the set of all scalar multiples of the nonzero vector <m>(a,b)</m>. Geometrically, this is the line that passes through the the origin and the point <m>(a,b)</m>.
            </p>
          </li>
          <li>
            <p>
              By definition
              <md>
                <mrow> \Span((1,0),(0,1))\amp =\{a(1,0)+b(0,1)\colon a,b\in \R\} </mrow>
                <mrow> \amp =\{(a,b)\colon a,b\in\R\}\amp</mrow>
              </md>.
            </p>
          </li>
          <li>
            <p>
              By definition
              <md>
                <mrow> \Span((1,1),(2,2))\amp =\{a(1,1)+b(2,2)\colon a,b\in \R\}</mrow>
                <mrow> \amp =\{(a+2b,a+2b)\colon a,b\in\R\} \amp </mrow>
              </md>.
              It is easy to see that this set is equal to <m>\{(c,c)\colon t\in \R\}</m>, the line with equation <m>y=x</m>. Note that in this case we have
              <me>
                \Span((1,1), (2,2))=\Span ((1,1))
              </me>,
              and thus that the vector <m>(2,2)</m> is in some sense redundant with respect to the span operation.
            </p>
          </li>
          <li>
            <p>
              By definition
              <md>
                <mrow>\Span((1,1),(1,2))\amp =\{a(1,1)+b(1,2)\colon a,b\in \R\}</mrow>
                <mrow> \amp =\{(a+b,a+2b)\colon a,b\in\R\} \amp </mrow>
              </md>.
              Claim: <m>\Span((1,1),(1,2))=\R^2</m>. Proving the claim amounts to showing that for all <m>(c,d)\in \R^2</m> there exist <m>a,b\in \R</m> such that
              <me>
                \begin{array}{ccccc}
                  a \amp +\amp b \amp =\amp c\\
                  a \amp +\amp 2b \amp =\amp d
                \end{array}
              </me>.
                Solving this system using Gaussian elimination, we see that the system has the unique solution
                <md>
                <mrow>
                  a\amp =2c-d \amp b\amp =d-c
                </mrow>
                </md>,
                and thus that
                <me>
                  (2c-d)(1,1)+(d-c)(1,2)=(c,d)
                </me>.
                This proves <m>\Span((1,1),(1,2))=\R^2</m>, as claimed.
              </p>
            </li>
            <li>
              <p>
                Observe first that in this case the index set for our tuple is <m>I=\R^2</m>, and the tuple <m>S</m> is of the form <m>S=(i)_{i\in I}</m>. In other words, the tuple in this case is the <q>list</q> of all elements of <m>\R^2</m>! 
                By <xref ref="rm_span"/>, we have <m>\{v_i\colon i\in I\}\subseteq \Span(v_i)_{i\in I}</m> for any tuple. Thus in this case 
                <me>
                    \{(a,b)\colon (a,b)\in \R^2\}\subseteq \Span((a,b))_{(a,b)\in \R^2}
                </me>.
                Since clearly <m>\{(a,b)\colon (a,b)\in \R^2\}=\R^2</m>, we see that <m>\R^2\subseteq \Span((a,b))_{(a,b)\in \R^2}</m>, from which it follows <m>\Span((a,b))_{(a,b)\in \R^2}=\R^2</m>. 
              </p>
            </li>
        </ol>
      </p>
      </solution>
    </example>
    <p>
      You may have noticed that each span computation in the previous example produced a subspace of <m>\R^2</m>. This is no accident!
    </p>
    <theorem xml:id="th_span">
    <title>Spans are subspaces</title>
    <statement>
    <p>
    Let <m>(v_i)_{i\in I}</m> be a tuple of vectors of the vector space <m>V</m>. 
    <ol>
      <li>
        <p>
          <m>\Span(v_i)_{i\in I}</m> is a subspace of <m>V</m>. 
        </p>
      </li>
      <li>
        <p>
          <m>\Span(v_i)_{i\in I}</m> is the smallest subspace of <m>V</m> containing <m>v_i</m> for all <m>i\in I</m> in the following sense: if <m>W</m> is a subspace of <m>V</m> and <m>v_i\in W</m> for all <m>i\in I</m>, then <m>\Span(v_i)_{i\in I}\subseteq W</m>. 
        </p>
      </li>
    </ol>
    </p>
    </statement>
    <proof>
    <p>
      <ol>
        <li>
          <p>
            We use <xref ref="proc_subspace"/>. As observed in <xref ref="rm_span"/>, we always have <m>\boldzero\in \Span(v_i)_{i\in I}</m>. Next, given <m>v,w\in \Span(v_i)_{i\in I}</m> we have by definition 
            <md>
              <mrow>v \amp =\sum_{i\in I}c_iv_i</mrow>
              <mrow>w \amp =\sum_{i\in I}d_iv_i</mrow>
            </md>
            where <m>c_i,d_i\in F</m> and <m>c_i=d_i=0</m> for all but finitely many <m>i\in I</m>. But then for any <m>c,d\in F</m>, we have 
            <me>
              cv+dw=\sum_{i\in I}(cc_i+dd_i)v_i
            </me>,
            and <m>cc_i+dd_i=0</m> for all but finitely many <m>i\in I</m>. Thus <m>cv+dw\in \Span(v_i)_{i\in I}</m>, as desired.
          </p>
        </li>
        <li>
          <p>
            If <m>W</m> is a subspace of <m>V</m> and <m>v_i\in W</m> for all <m>i\in I</m>, then since <m>W</m> is closed under addition and scalar multiplication, <m>W</m> contains all linear combinations of the <m>v_i</m>. Thus <m>W</m> contains <m>\Span(v_i)_{i\in I}</m>: <ie/>, <m>\Span(v_i)_{i\in I}\subseteq W</m>. 
          </p>
        </li>
      </ol>
    </p>
    </proof>
    </theorem>
    <definition xml:id="d_spanning_tuple">
    <title>Spanning set</title>
    <statement>
    <p>
    Let <m>W</m> be a subspace of the vector space <m>V</m>. A <term>spanning set</term> of <m>W</m> is a tuple <m>(v_i)_{i\in I}</m> of vectors of <m>V</m> such that <m>W=\Span(v_i)_{i\in I}</m>.  
    </p>
    </statement>
    </definition>
    <remark xml:id="rm_spanning_sets">
    <title>Standard spanning sets</title>
    <p>
      Most of the vector spaces we've introduced there is a natural spanning set that comes to mind. We will refer to these loosely as <em>standard</em> spanning sets.
      <ul>
        <li>
          <title>Zero space</title>
          <p>
          Let <m>V=\{\boldzero\}</m>. By definition the empty list <m>S=()</m> is a spanning set of <m>V</m>.
          </p>
        </li>
        <li>
          <title>Tuples</title>
          <p>
          Let <m>V=F^n</m>. For <m>1\leq i\leq n</m>, define <m>\bolde_i</m> to be the <m>n</m>-tuple with a one in the <m>i</m>-th entry, and zeros elsewhere. Then <m>S=(\bolde_1, \bolde_2,\dots, \bolde_n)</m> is a spanning set for <m>F^n</m>.
          </p>
        </li>
        <li>
          <title>Matrices</title>
          <p>
          Let <m>V=F^{m,n}</m>. For each <m>(i,j)</m> with <m>1\leq i\leq m</m> and <m>1\leq j\leq n</m>, define <m>E(i,j)</m> to be the <m>m\times n</m> matrix with a one in the <m>ij</m>-th entry, and zeros elsewhere. Then <m>S=(E_{ij})_{\substack{1\leq i\leq m\\ 1\leq j\leq m}}</m> is a spanning set for <m>F^{m,n}</m>.
          </p>
        </li>
        <li>
          <title>Polynomials</title>
          <p>
          Let <m>F\in \{\R,\C\}</m>, and let <m>I</m> be an infinite subset of <m>F</m>. The tuple <m>S=(x^{i})_{i=0}^n=(1,x,x^2,\dots, x^n)</m> is a spanning set <m>P_n(I)</m>, as by definition the elements of <m>P_n(I)</m> are functions of the form <m>f(x)=\anpoly</m>. 
          </p>
          <p>
            Similarly, the tuple <m>(x^i)_{i=0}^\infty=(1,x,x^2,\dots)</m> is a spanning set of <m>P(I)</m>. 
          </p>
        </li>
      </ul>
      </p>
    </remark>
    <p>
      It is important to observe that spanning sets for vector spaces are not unique. Far from it! In general, for any nonzero vector space there are infinitely many choices of spanning sets.
    </p>
    <example>
      <title>Spanning sets are not unique</title>
      <statement>
        <p>
        For each <m>V</m> and <m>S</m> below, verify that <m>S</m> is a spanning set for <m>V</m>.
        <ol>
          <li>
            <p>
              <m>V=\R^2</m>, <m>S=\{(1,1), (1,2)\}</m>
            </p>
          </li>
          <li>
            <p>
              <m>V=M_{22}</m>, <m>S=\{A_1, A_2, A_3, A_4\}</m>,
              <me>
                A_1=\begin{amatrix}[rr]1\amp 1\\ 1\amp 1  \end{amatrix},
                A_2=\begin{amatrix}[rr]1\amp -1\\ 0\amp 0  \end{amatrix},
                A_3=\begin{amatrix}[rr]0\amp 0\\ 1\amp -1  \end{amatrix},
                A_4=\begin{amatrix}[rr]1\amp 1\\ -1\amp -1  \end{amatrix}
              </me>.
            </p>
          </li>
          <!-- <li>
            <p>
              <m>V=P_2</m>, <m>S=\{x^2+x+1, x^2-x, x-1\}</m>
            </p>
          </li> -->
        </ol>
        </p>
      </statement>
      <solution>
        <p>
          <ol>
            <li>
              <p>
                This was shown in <xref ref="eg_span_2space"/>
              </p>
            </li>
            <li>
              <p>
                We must show, given any <m>A=\begin{amatrix}[rr]a\amp b\\ c\amp d  \end{amatrix}</m>, we can find <m>c_1, c_2, c_3, c_4\in \R</m> such that
                <me>
                  c_1A_1+c_2A_2+c_3A_3+c_4A_4=\begin{amatrix}[rr]a\amp b\\ c\amp d  \end{amatrix}
                </me>,
                or
                <me>
                  \begin{amatrix}[rr]c_1+c_2+c_4 \amp c_1-c_2+c_4\\
                  c_1+c_3-c_4\amp c_1-c_3-c_4  \end{amatrix}
                  =
                  \begin{amatrix}[rr]a\amp b \\ c\amp d  \end{amatrix}
                </me>.
                We can find such <m>c_i</m> if and only if the system with augmented matrix
                <me>
                  \begin{amatrix}[rrrr|r]
                  1\amp 1\amp 0\amp 1\amp a\\
                  1\amp -1\amp 0\amp 1\amp b \\
                  1\amp 0\amp 1\amp -1\amp c\\
                  1\amp 0\amp -1\amp -1\amp d
                \end{amatrix}
                </me>
                is consistent. This matrix row reduces to
                <me>
                \begin{amatrix}[rrrr|r]
                \boxed{1}\amp 1\amp 0\amp 1\amp a\\
                0\amp \boxed{1}\amp 0\amp 0\amp \frac{a-b}{2} \\
                0\amp 0\amp \boxed{1}\amp -2\amp c-\frac{a+b}{2}\\
                0\amp 0\amp 0\amp \boxed{1}\amp \frac{a+b-c-d}{4}
              \end{amatrix}
                </me>.
                Since the last column will never contain a leading one, we conclude that the system is consistent for any choice of <m>a,b,c,d</m>, and thus that <m>\Span S=M_{22}</m>, as claimed.
              </p>
            </li>
            <!-- <li>
              <p>
                We must show that given any <m>p(x)=ax^2+bx+c</m> we can find <m>c_1,c_2,c_3</m> such that
                <me>
                  c_1(x^2+x+1)+c_2(x^2-1)+c_3(x-1)=ax^2+bx+c
                </me>,
                or
                <me>
                  (c_1+c_2)x^2+(c_1+c_3)x+(c_1-c_2-c_3)=ax^2+bx+c
                </me>.
                According to <xref ref="th_poly_equality"/> this equality holds if and only if
                <me>
                  \begin{linsys}{3}
                    c_1 \amp +\amp c_2 \amp  \amp \amp = \amp a\\
                    c_1 \amp \amp \amp + \amp c_3 \amp = \amp b\\
                    c_1 \amp -\amp c_2 \amp - \amp c_3 \amp = \amp c
                  \end{linsys}
                </me>.
                As in the examples above, our reasoning implies  <m>\Span S=P_2</m> if and only if this system is consistent for <em>any</em> choice of <m>a,b,c</m>. Thus usual Gaussian elimination procedure tells us that this is indeed so. We leave the details to you.
              </p>
            </li> -->
          </ol>
        </p>
      </solution>
    </example>
    </subsection>
    <subsection xml:id="ss_lin_ind">
    <title>Linear independence</title>
    <p>
      As mentioned above, the notion of <em>linear independence</em> is precisely what we need to guarantee that a given spanning set <m>S=(v_i)_{i\in I}</m> has no <q>redundancies</q>. This is not immediately evident from the definition, but will be made clear in ......
    </p>
    <definition xml:id="d_lin_ind">
    <title>Linear independence</title>
    <statement>
    <p>
    A tuple <m>S=(v_i)_{i\in i}</m> of vectors of the vector space <m>V</m> is <term>linearly independent</term> if there is no nontrivial linear combination of the <m>v_i</m> equal to <m>\boldzero</m>: <ie/>, if <m>\sum_{i\in I}c_iv_i</m> is a linear combination satisfying <m>\sum_{i\in I}c_iv_i=\boldzero</m>, then <m>c_i=0</m> for all <m>i\in I</m>. Using logical shorthand: 
    <men xml:id="eq_lin_ind">
      \sum_{i\in I}c_iv_i=\boldzero\implies c_i=0 \text{ for all } i\in I
    </men>.
    We say <m>(v_i)_{i\in I}</m> is <term>linearly dependent</term> if it is not linearly independent: <ie/>, if there is a nontrivial linear combination <m>\sum_{i\in I}c_iv_i=\boldzero</m>. 
    </p>
    <p>
        Lastly, observe that an empty list <m>S=()</m> of vectors is linearly independent as it satisfies the implication <xref ref="eq_lin_ind"/> vacuously. 
    </p>
    </statement>
    </definition>
    
    <algorithm xml:id="proc_linear_independence">
  <title>Linear independence of a finite set</title>
  <statement>
    <p>Let <m>S=(v_i)_{i\in I}</m> be a tuple of vectors of the vector space <m>V</m>. To decide whether <m>S</m> is linearly independent, proceed as follows. 
    <ol>
      <li>
        <p>
          Write out the general expression for a linear combination of the form
          <me>
          c_{i_1}\boldv_{i_1}+c_{i_2}\boldv_{i_2}+\cdots +c_{i_n}\boldv_{i_n}=\boldzero
          </me>.
        </p>
      </li>
      <li>
        <p>
          If possible, translate this vector equation into a homogeneous system of linear equations in the unknowns <m>c_{i_1},c_{i_2},\dots, c_{i_n}</m>, using the definition of equality for your vector space.
        </p>
      </li>
      <li>
        <p>
          Decide, using Gaussian elimination, whether this system has any nonzero (<ie />, nontrivial) solutions. If it has no nontrivial solution, <m>S</m> is linearly independent; if it has a nontrivial solution, <m>S</m> is linearly dependent. 
        </p>
      </li>
    </ol>
  </p>
  </statement>
</algorithm>

    <example xml:id="ex_linear_independence">
    <title>Linear independence</title>
    <statement>
      <p>
        For each tuple <m>S</m> of the given vector space <m>V</m>, decide whether <m>S</m> is linearly independent.
      <ol>
        <li>
          <p>
            <m>V=\R^3</m>, <m>S=((1,1,2),(1,0,1), (-2,1,-1))</m>
          </p>
        </li>
  
        <li>
          <p>
            <m>V=\R^{2,2}</m>, <m>S=(A_1, A_2, A_3)</m>, where
            <me>
              A_1=\begin{bmatrix}3\amp 1\\ 2\amp -3 \end{bmatrix} , A_2= \begin{bmatrix}0\amp 4\\ 2\amp 0 \end{bmatrix} , A_3=\begin{bmatrix}-2\amp -2\\ -2\amp 2 \end{bmatrix}
            </me>.
          </p>
        </li>
        <li>
          <p>
            <m>V=P(\R)</m>, <m>S=(x^i)_{i=0}^\infty=(1,x,x^2,\dots)</m>
          </p>
        </li>
      </ol>
    </p>
    </statement>
    <solution>
    <p>
      <ol>
      <li>
        <p>
        We have
        <me>
          a(1,1,2)+b(1,0,1)+c(-2,1,-1)=(0,0,0)
        </me>
        if and only if
        <me>
          \begin{linsys}{3}
            a \amp +\amp b\amp -\amp 2c\amp =0\\
            a \amp \amp \amp +\amp c\amp =0\\
            2a \amp +\amp b\amp -\amp c\amp =0\\
          \end{linsys}
        </me>.
        After a little Gaussian elimination we see that
        <m>(a,b,c)=(1,-3,-1)</m> is a nonzero solution to this system, and thus that
        <me>
          (1,1,2)-3(1,0,1)-(-2,1,-1)=(0,0,0)
        </me>
        is a nontrivial linear combination equal to <m>\boldzero</m>. We conclude that <m>S</m> is linearly dependent.
        </p>
      </li>
      
      <li>
        <p>
          We have  <m>aA_1+bA_2+cA_3=\boldzero</m> if and only if 
          <md>
            <mrow>a\begin{bmatrix}3\amp 1\\ 2\amp -3 \end{bmatrix} +b\begin{bmatrix}0\amp 4\\ 2\amp 0 \end{bmatrix} +c\begin{bmatrix}-2\amp -2\\ -2\amp 2 \end{bmatrix}\amp = \begin{bmatrix}0\amp 0\\0\amp 0 \end{bmatrix}
            \amp </mrow>
          </md>,
          if and only if 
          <md>
            <mrow>
            \begin{bmatrix}3a-2c\amp a+4b-2c\\ 2a+2b-2c\amp -3a+2c \end{bmatrix}\amp =\begin{bmatrix}0\amp 0\\0\amp 0 \end{bmatrix} \amp </mrow>
          </md>.
          Gaussian elimination reveals that the corresponding system of equations 
          <me>
             \begin{linsys}{3} 3a\amp \amp \amp -\amp 2c\amp =\amp 0\\ a\amp +\amp 4b\amp -\amp 2c\amp =\amp 0\\ 2a\amp +\amp 2b \amp -\amp 2c \amp =\amp 0\\ -3a\amp \amp \amp +\amp 2c\amp =\amp 0 \end{linsys} 
          </me>
         has infinitely many solutions, and thus nontrivial solutions (<eg/>, <m>(a,b,c)=(2,1,3)</m>). We conclude that there is a nontrivial combination of the <m>A_i</m> equal to <m>\boldzero</m>, and hence that <m>S</m> is linearly dependent.
        </p>
      </li>
    </ol>
    </p>
    </solution>
  </example>
  <theorem xml:id="th_span_ind">
  <title>Span and independence</title>
  <statement>
  <p>
  Let <m>S=(v_i)_{i\in I}</m> be a nonempty tuple of vectors of the vector space <m>V</m>. The following statements are equivalent. 
  <ol>
    <li>
        <p>
            <m>S</m> is linearly dependent.
        </p>
    </li>
    <li>
        <p>
            There is an index <m>i_{0}\in I</m> such that <m>v_{i_{0}}</m> can be written as a linear combination of the other <m>v_i</m>'s: <ie/>, there exists <m>i_k\in I</m> such that <m>v_{i_k}\in \Span(v_i)_{i\in I-\{i_k\}}</m>. Furthermore, in this case we have 
            <men xml:id="eq_span_ind">
                \Span(v_i)_{i\in I}=\Span(v_i)_{i\in I-\{i_k\}}
            </men>.
        </p>
    </li>
    
  </ol>
  </p>
  </statement>
  <proof>
  <p>
    If the tuple <m>S=(v_i)_{i\in I}</m> is linearly dependent, then there is a nontrivial linear combination 
    <me>
      c_{i_1}v_1+c_{i_2}v_2+\cdots +c_{i_n}v_{i_n}=\boldzero
    </me>,
    where <m>i_j\in I</m>. 
    Since the linear combination is nontrivial, we have <m>c_{i_k}\ne 0</m> for some <m>1\leq k\leq n</m>. After a little vector arithmetic, we can then solve for <m>v_{i_k}</m>: 
    <me>
      v_{i_k}=\sum_{j\ne k}\frac{c_{i_j}}{c_{i_k}}v_{i_j}
    </me>.
    This shows <m>v_{i_k}</m> is a linear combination of the vectors <m>v_i</m>, where <m>i\ne i_k</m>, and thus that <m>v_{i_k}\in \Span(v_i)_{i\in I-\{i_k\}}</m>.
  </p>
  <p>
    Conversely, if we have <m>v_{i_k}\in \Span(v_i)_{i\in I-\{i_k\}}</m>, then we have 
    <men xml:id="eq_span_ind_proof">
      v_{i_k}=\sum_{j=1}^nd_{i_j}v_{i_j}
    </men>
    for some <m>i_j\in I</m> and <m>d_{i_j}\in F</m>, whence it follows that 
    <me>
      -d_{i_1}v_{i_1}-d_{i_2}v_{i_2}-\cdots --d_{i_n}v_{i_n}+v_{i_k}=\boldzero
    </me>
    is a nontrivial linear combination of the <m>v_i</m> equal to <m>\boldzero</m>. We conclude that <m>S=(v_i)_{i\in i}</m> is linearly dependent.
  </p>
  <p>
    We have thus proved that <m>S</m> is linearly dependent if and only if some <m>v_{i_k}</m> can be written as a linear combination of the other vectors <m>v_i</m>. We now prove that when this is the case, we have 
    <me>
      \Span(v_i)_{i\in I-\{i_k\}}=\Span(v_i)_{i\in I}
    </me>.
    Using statement (2) of <xref ref="th_span"/>, since <m>\Span(v_i)_{i\in I}</m> is a subspace and contains <m>v_i</m> for all <m>i\in I-\{i_k\}</m>, we have 
    <me>
      \Span(v_i)_{i\in I-\{i_k\}}\subseteq \Span(v_i)_{i\in I}
    </me>.
    For the other direction, take <m>v\in \Span(v_i)_{i\in I}</m>. By definition, we can write <m>v</m> as a finite linear combination of the vectors <m>v_i</m>. It follows that can write 
    <me>
      v=c_{i_k}v_{i_k}+\sum_{i\in J}c_iv_i
    </me>,
    where <m>J</m> is a finite subset of <m>I</m> not containing <m>i_k</m>. (Note that <m>c_{i_k}</m> is allowed to be 0 here.) Since <m>v_{i_k}</m> is assumed to be a linear combination of the other vectors <m>v_i</m>, we can express <m>v_{i_k}</m> as in <xref ref="eq_span_ind_proof"/>, in which case we have 
    <me>
      v=\sum_{j=1}^nc_{i_k}d_{i_j}v_{i_j}+\sum_{i\in J}c_iv_i
    </me>.
    Since <m>i_j\ne i_k</m> for all <m>1\leq j\leq n</m>, and since <m>i_k\notin J</m>, we see that this is a linear combination of the tuple <m>(v_i)_{i\in I-\{i_k\}}</m>. Thus <m>v\in \Span(v_i)_{i\in I-\{i_k\}}</m>, showing that 
    <me>
      \Span(v_i)_{i\in I}\subseteq \Span(v_i)_{i\in I-\{i_k\}}
    </me>,
    as desired.
  </p>
  </proof>
  </theorem>
  <p>
    <xref ref="th_span_ind"/> is a precise articulation of the fact that a tuple <m>S=(v_i)_{i\in I}</m> is linearly dependent if and only if one of the vectors <m>v_{i_0}</m> is <q>redundant</q>. In more detail, it says that there is an index <m>i_0</m> such that 
    <me>
        v_{i_0}=c_{i_1}v_{i_1}+c_{i_2}v_{i_1}+\cdots +c_{i_n}v_{i_1}
    </me>
    where <m>i_k\ne i_0</m> for all <m>1\leq k\leq n</m>, and furthermore, that in terms of the span operation, this <q>redundant</q> vector <m>v_{i_0}</m> can be dropped. We will most often apply this result in the case where we have a tuple of finite length. We record the result in this special case as a corollary.
  </p>
  <corollary xml:id="cor_span_ind">
    <title>Span and independence</title>
    <statement>
        <p>
            Let <m>S=(v_1,v_2,\dots, v_n)</m> be an <m>n</m>-tuple of vectors of the vector space <m>V</m>. The following statements are equivalent. 
            <ol>
                <li>
                    <p>
                        <m>S</m> is linearly dependent. 
                    </p>
                </li>
                <li>
                    <p>
                        There exists <m>k\in \{1,2,\dots, n\}</m> such that 
                        <men>
                            v_k\in \Span(v_1,v_2,\dots, v_{k-1})
                        </men>.
                        Furthermore, when this is the case we have 
                        <men xml:id="eq_span_ind_finite">
                            \Span(v_1,v_2,\dots, v_n)=\Span(v_i)_{i\ne k}
                        </men>.
                        In other words, the span of the vectors is unchanged when we drop the <q>redundant</q> vector <m>v_k</m>. 
                    </p>
                </li>
            </ol>
        </p>
    </statement>
  </corollary>
  <remark>
    <p>
      For the case <m>k=1</m> in the statement of <xref ref="cor_span_ind"/>, we interpret the assertion 
    <me>
      v_k\in \Span(v_1,v_2,\dots, v_{k-1})
    </me>
    as <m>v_1\in \Span()</m>. In this somewhat degenerate case, it turns out that we must have <m>v_1=\boldzero</m>. See the proof below. 
  </p>
  </remark>
  <proof>
    <title>Proof of corollary</title>
    <p>
      The corollary is for the most part simply a special case of <xref ref="th_span_ind"/>. It remains only to prove that if <m>S=(v_1,v_2,\dots, v_n)</m> is linearly dependent, then there is a <m>1\leq k\leq n</m> such that 
      <me>
        v_k\in\Span(v_1,v_2,\dots, v_{k-1})
      </me>.
      This is proven as follows: if <m>S</m> is linearly dependent, then we have a nontrivial linear combination
      <me>
        c_1v_1+c_2v_2+\cdots +c_nv_n=\boldzero
      </me>.
      Since <m>c_i\ne 0</m> for <em>some</em> <m>i</m>, we can set <m>k</m> to be the largest such <m>i</m>: <ie/>, 
      <me>
        k=\max\{i\in \{1,2,\dots, n\}\colon c_i\ne 0\}
      </me>.
      We now treat the cases <m>k=1</m> and <m>k&gt; 1</m> separately. If <m>k=1</m>, then by definition of <m>k</m>, we have <m>c_1v_1=\boldzero</m> and <m>c_1\ne 0</m>. Using <xref ref="th_vs_props"/>, we conclude that <m>v_1=\boldzero</m> in this case, and hence that <m>v_1\in \Span()=\{\boldzero\}</m>. (When <m>k=1</m> we interpret <m>\Span(v_1,\dots, v_{k-1})</m> as <m>\Span()</m>.)
    </p>
      <p>
        Now assume <m>k\geq 2</m>. By definition of <m>k</m>, we have 
      <me>
        c_1v_1+\cdots +c_kv_k=\boldzero
      </me>
      and <m>c_k\ne 0</m>, from whence it follows that  
      <me>
        v_k=-\frac{c_1}{c_k}v_1+\cdots -\frac{c_{k-1}}{c_k}v_{k-1}\in \Span(v_1,v_2,\dots, v_{k-1})
      </me>,
      as desired.
    </p>
  </proof>
    </subsection>

</section>